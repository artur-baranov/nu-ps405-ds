[
  {
    "objectID": "ps405-d_1.html",
    "href": "ps405-d_1.html",
    "title": "Last Quarter’s Review",
    "section": "",
    "text": "We are expected to have installed R and RStudio, if not see the installing R section.\nIn the discussion section, we will focus on coding and practicing what we have learned in the lectures.\nOffice hours are on Tuesday, 11-12:30 Scott 110.\nQuestions?\n\n\nDownload script"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PS405 Linear Models",
    "section": "",
    "text": "This site is designed to support students enrolled in the PS405 Linear Models course. Here, you will find lab materials, which are also available on Canvas. In the section, we will focus on coding and practicing the concepts covered in the lectures.\n\n\n\n\n\n   Thursday\n   11:00 AM – 11:50 AM\n   Scott Hall 212\n\n\n\n\n\n\n   Tuesday\n   11:00 AM – 12:30 PM\n   Scott Hall 110"
  },
  {
    "objectID": "ps405-d_1.html#terminology",
    "href": "ps405-d_1.html#terminology",
    "title": "Last Quarter’s Review",
    "section": "Terminology",
    "text": "Terminology"
  },
  {
    "objectID": "ps405-d_1.html#coding-terminology",
    "href": "ps405-d_1.html#coding-terminology",
    "title": "Last Quarter’s Review",
    "section": "Coding Terminology",
    "text": "Coding Terminology\n\nCode Chunk\nTo insert a Code Chunk, you can use Ctrl+Alt+I on Windows and Cmd+Option+I on Mac. Run the whole chunk by clicking the green triangle, or one/multiple lines by using Ctrl + Enter or Command + Return on Mac.\n\nprint(\"Code Chunk\")\n\n[1] \"Code Chunk\"\n\n\n\n\nFunction and Arguments\nMost of the functions we want to run require an argument For example, the function print() above takes the argument “Code Chunk”.\n\nfunction(argument)\n\n\n\nData structures\nThere are many data structures, but the most important to know the following.\n\nObjects. Those are individual units, e.g. a number or a word.\n\n\nnumber = 1\nnumber\n\nword = \"Northwestern\"\nword\n\n[1] 1\n[1] \"Northwestern\"\n\n\n\nVectors. Vectors are collections of objects. To create one, you will need to use function c().\n\n\nnumbers = c(1, 2, 3)\nnumbers\n\n[1] 1 2 3\n\n\n\nDataframes. Dataframes are the most used data structure. Last quarter you spend a lot of time working with it. It is a table with data. Columns are called variables, and those are vectors. You can access a column using $ operator.\n\n\ndf = data.frame(numbers, \n                numbers_multiplied = numbers * 2)\ndf\ndf$numbers_multiplied\n\n  numbers numbers_multiplied\n1       1                  2\n2       2                  4\n3       3                  6\n[1] 2 4 6\n\n\n\n\nData classes\nWe work with various classes of data, and the analysis we perform depends heavily on these classes.\n\nNumeric. Continuous data.\n\n\nnumeric_class = c(1.2, 2.5, 7.3)\nnumeric_class\nclass(numeric_class)\n\n[1] 1.2 2.5 7.3\n[1] \"numeric\"\n\n\n\nInteger. Whole numbers (e.g., count data).\n\n\ninteger_class = c(1:3)\nclass(integer_class)\n\n[1] \"integer\"\n\n\n\nCharacter. Usually, represent textual data.\n\n\nword\n\n[1] \"Northwestern\"\n\nclass(word)\n\n[1] \"character\"\n\n\n\nFactor. Categorical variables, where each value is treated as an identifier for a category.\n\n\ncolors = c(\"blue\", \"green\")\nclass(colors)\n\n[1] \"character\"\n\n\nAs you noticed, R did not identify the class of data correctly. We can change it using as.factor() function. You can easily change the class of your variable (as.numeric(), as.integer(), as.character())\n\ncolors = as.factor(colors)\nclass(colors)\n\n[1] \"factor\"\n\n\n\n\nLibraries\nQuite frequently, we use additional libraries to extend the capabilities of R. I’m sure you remember tidyverse. Let’s load it.\n\nlibrary(tidyverse)\n\nIf you updated your R or recently downloaded it, you can easily install libraries using the function install.packages().\n\n\nPipes\nPipes (%&gt;% or |&gt;) are helpful for streamlining the coding. They introduce linearity to the process of writing the code. In plain English, a pipe translates to “take an object, and then”.\n\nnumbers %&gt;%\n  print()\n\n[1] 1 2 3"
  },
  {
    "objectID": "ps405-d_2.html",
    "href": "ps405-d_2.html",
    "title": "Simple Linear Regression",
    "section": "",
    "text": "Download the data\nOrganize your directory\n\n\nDownload script\n\n\n\nDownload data"
  },
  {
    "objectID": "ps405-d_2.html#model-building",
    "href": "ps405-d_2.html#model-building",
    "title": "Simple Linear Regression",
    "section": "Model Building",
    "text": "Model Building\nLet’s run a simple model, and then check it’s summary.\n\nbasic_model = lm(Ladder_score ~ Social_support, whr)\n  \nsummary(basic_model)\n\n\nCall:\nlm(formula = Ladder_score ~ Social_support, data = whr)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.76562 -0.36701  0.01165  0.46577  1.49971 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     -0.3428     0.3386  -1.013    0.313    \nSocial_support   7.3618     0.4183  17.599   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6304 on 135 degrees of freedom\nMultiple R-squared:  0.6964,    Adjusted R-squared:  0.6942 \nF-statistic: 309.7 on 1 and 135 DF,  p-value: &lt; 2.2e-16\n\n\nA one unit increase in Social Support is associated with a 7.4 increase in the happiness score. What is the maximum value the Happiness Score can take?\n\nmax(whr$Ladder_score)\n\n[1] 7.804\n\n\nAnd now, let’s draw a histogram of the Social Support. So, how much does this model tell us?\n\nggplot(whr) +\n  ...(aes(x = Social_support))\n\nLet’s correct the Social_support variable a bit, transforming it to 0-100 scale. What do you think about the model now? What do you think about \\(R^2\\)?\n\nwhr = whr %&gt;%\n  mutate(Social_support_percentage = Social_support * 100)\n\nadjusted_model = lm(Ladder_score ~ Social_support_percentage, whr)\n  \nsummary(adjusted_model)\n\n\nCall:\nlm(formula = Ladder_score ~ Social_support_percentage, data = whr)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.76562 -0.36701  0.01165  0.46577  1.49971 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)               -0.342811   0.338568  -1.013    0.313    \nSocial_support_percentage  0.073618   0.004183  17.599   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6304 on 135 degrees of freedom\nMultiple R-squared:  0.6964,    Adjusted R-squared:  0.6942 \nF-statistic: 309.7 on 1 and 135 DF,  p-value: &lt; 2.2e-16\n\n\nLet’s write this regression formula out. Do you remember the general form?\n\\[\nY = \\beta_0 + \\beta_1X_1+\\epsilon\n\\]\nIn our case, this can be presented as\n\\[\n\\text{Happines} = -0.34 + 0.07\\text{ Social Support} + e\n\\]\nAlternatively,\n\\[\nY = -0.34+0.07x+u\n\\]\nNow, visualize the regression.\n\nggplot(whr, aes(x = Social_support_percentage, y = Ladder_score)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(x = \"Social Support (%)\",\n       y = \"Happiness Score\")"
  },
  {
    "objectID": "ps405-d_2.html#diagnostics",
    "href": "ps405-d_2.html#diagnostics",
    "title": "Simple Linear Regression",
    "section": "Diagnostics",
    "text": "Diagnostics\nLet’s analyze the regression. First, extract the residuals and plot their distribution. Does it follow \\(N(0, \\sigma^2)\\)?\n\nres = adjusted_model$residuals\n\nggplot() +\n  geom_histogram(aes(x = res), bins = 20) +\n  geom_vline(xintercept = mean(res), color = \"red\", size = 1.5)\n\n\n\n\n\n\n\n\nNow we need to check the constant variance assumption. Does it hold? What term is used to describe this satisfied assumption?\n\nyhat = adjusted_model$fitted.values\n\nggplot() +\n  geom_point(aes(x = yhat, y = res)) +\n  geom_hline(yintercept = 0, color = \"blue\") +\n  labs(title = \"Residuals vs fitted values plot\")\n\n\n\n\n\n\n\n\nExplore different patterns below"
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "PS405 Linear Models",
    "section": "Schedule",
    "text": "Schedule\n\n\n\n\n\nWeek\n\n\nTitle\n\n\nLink\n\n\nCode\n\n\nData\n\n\n\n\n\n\n1\n\n\nLast Quarter’s Review\n\n\n\n\n\n\n\n\n \n\n\n\n\n2\n\n\nSimple Linear Regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n3\n\n\nMultiple Linear Regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n4\n\n\nReview and Confidence Intervals\n\n\n\n\n\n\n\n\n\n\n\n\n\n5\n\n\nPresenting Results of Regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n6\n\n\nRobust Standard Errors\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#description",
    "href": "index.html#description",
    "title": "PS405 Linear Models",
    "section": "",
    "text": "This site is designed to support students enrolled in the PS405 Linear Models course. Here, you will find lab materials, which are also available on Canvas. In the section, we will focus on coding and practicing the concepts covered in the lectures.\n\n\n\n\n\n   Thursday\n   11:00 AM – 11:50 AM\n   Scott Hall 212\n\n\n\n\n\n\n   Tuesday\n   11:00 AM – 12:30 PM\n   Scott Hall 110"
  },
  {
    "objectID": "index.html#additional-resources",
    "href": "index.html#additional-resources",
    "title": "PS405 Linear Models",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nHelpful Regression Resources\n\nStep-by-step regression guide\n\n\n\nData Wrangling\n\nJoins Tutorial\n\n\n\nData sources\n\nPolitical Science datasets\n\n\n\nVisualization\n\nIntroduction to ggplot2\nMaps/Networks/Advanced vizualisation with ggplot2\nMaking interactive plots with ggplot2"
  },
  {
    "objectID": "ps405-d_3.html",
    "href": "ps405-d_3.html",
    "title": "Multiple Linear Regression",
    "section": "",
    "text": "Congrats with submitting the first HW! How are you feeling?\nThe discussion section structure (review, comments about HW, new material and exercises). I would be happy to hear your feedback after the classes or via email.\n\n\nDownload script\n\n\n\nDownload data"
  },
  {
    "objectID": "ps405-d_3.html#fixed-effects",
    "href": "ps405-d_3.html#fixed-effects",
    "title": "Multiple Linear Regression",
    "section": "Fixed Effects",
    "text": "Fixed Effects\nLet’s explore how leader’s tenure is associated with the number of individuals in the government. We start with the simple linear regression. Take a moment to interpret the result and \\(R^2\\).\n\nlm(n_individuals ~ leaderexperience_continuous, whogov) %&gt;%\n  summary()\n\n\nCall:\nlm(formula = n_individuals ~ leaderexperience_continuous, data = whogov)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-28.666  -6.937  -1.937   5.301 109.063 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 23.59948    0.16232  145.39   &lt;2e-16 ***\nleaderexperience_continuous  0.33702    0.01627   20.71   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.21 on 9151 degrees of freedom\nMultiple R-squared:  0.04477,   Adjusted R-squared:  0.04467 \nF-statistic: 428.9 on 1 and 9151 DF,  p-value: &lt; 2.2e-16\n\n\nTake a moment and draw a scatterplot for n_individuals and leaderexperience_continuous. Add a regression line to the plot.\n\n...\n\nNow, let’s add a categorical variable, indep, to the model. By doing so, we assume that the association between the leader’s tenure and the number of individuals in the government differs depending on whether the leader is independent or partisan.\nPractically, this could be done in multiple ways. First, let’s discuss introduction of fixed effects to our model. Moreover, this is a Multiple linear regression!\n\nmodel_fe = lm(n_individuals ~ leaderexperience_continuous + indep, whogov) \nsummary(model_fe)\n\n\nCall:\nlm(formula = n_individuals ~ leaderexperience_continuous + indep, \n    data = whogov)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.437  -7.078  -1.796   5.377 108.632 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 24.01096    0.16605  144.60   &lt;2e-16 ***\nleaderexperience_continuous  0.35700    0.01617   22.08   &lt;2e-16 ***\nindepIndependent            -3.02909    0.29988  -10.10   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.06 on 9126 degrees of freedom\n  (24 observations deleted due to missingness)\nMultiple R-squared:  0.05649,   Adjusted R-squared:  0.05628 \nF-statistic: 273.2 on 2 and 9126 DF,  p-value: &lt; 2.2e-16\n\n\nWe will use ggeffects library for visualization of regression with the fixed effects. This is sort of an addition to ggplot2 library from tidyverse. Don’t forget to install it using install.packages()!\n\nlibrary(ggeffects)\n\nThen, visualize the result. What can we see?\n\nggpredict(model_fe, terms = c(\"leaderexperience_continuous\", \"indep\")) %&gt;%\n  plot()\n\n\n\n\n\n\n\n\nLet’s customize the plot. It should be relatively straightforward given we know ggplot functions. Details for the customization of plot() function can be found on ggeffects website.\n\nggpredict(model_fe, terms= c(\"leaderexperience_continuous\", \"indep\")) %&gt;%\n  plot(show_ci = F) +\n  labs(title = \"Fixed Effects Regression\",\n       x = \"Tenure of a Leader\",\n       y = \"Number of Individuals in a Cabinet\",\n       color = \"Leader's Status\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nSome common fixed effects include:\n\nCountry/Region/State\nIndividual leaders/Parties\nYear/Time\nPolicy presence or absence\n\nBy introducing fixed effects, we are able to control for unobserved confounders that vary across the units (not within!)."
  },
  {
    "objectID": "ps405-d_3.html#interactions",
    "href": "ps405-d_3.html#interactions",
    "title": "Multiple Linear Regression",
    "section": "Interactions",
    "text": "Interactions\nOften dummy variables are used to introduce an interaction term in the model. We will explore the association between Perceptions_of_corruption and number of people in the cabinet (n_individuals) depending on the independence of the party leader.\nThe task isn’t trivial as now we planning to use data from two datasets, Let’s subset those.\n\nwhr_subset = whr %&gt;%\n  select(Country_name, Perceptions_of_corruption)\n\nwhogov_subset = whogov %&gt;%\n  filter(year == 2021) %&gt;%\n  select(country_name, n_individuals, indep)\n\nNow, we are merging them. It’s not easy to understand what’s going on, but here is a great resource on joins (check “the {dplyr} way”)!\n\nwhr_whogov = whr_subset %&gt;%\n  left_join(whogov_subset, by = c(\"Country_name\" = \"country_name\")) \n\nCheck the result\n\nhead(whr_whogov)\n\n  Country_name Perceptions_of_corruption n_individuals           indep\n1      Finland                     0.182            23 Non-independent\n2      Denmark                     0.196            24 Non-independent\n3      Iceland                     0.668            15 Non-independent\n4       Israel                     0.708            33 Non-independent\n5  Netherlands                     0.379            18 Non-independent\n6       Sweden                     0.202            26 Non-independent\n\n\nNow, to interact variables we need to use asterisk *, i.e. multiplication.\n\nmodel_in = lm(Perceptions_of_corruption ~ n_individuals * indep, whr_whogov)\nsummary(model_in)\n\n\nCall:\nlm(formula = Perceptions_of_corruption ~ n_individuals * indep, \n    data = whr_whogov)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.54000 -0.05737  0.04300  0.10864  0.24382 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                     0.575192   0.061646   9.331 5.59e-16 ***\nn_individuals                   0.004818   0.002151   2.240   0.0269 *  \nindepIndependent                0.386220   0.159570   2.420   0.0170 *  \nn_individuals:indepIndependent -0.010703   0.005501  -1.946   0.0540 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1737 on 123 degrees of freedom\n  (10 observations deleted due to missingness)\nMultiple R-squared:  0.08324,   Adjusted R-squared:  0.06088 \nF-statistic: 3.723 on 3 and 123 DF,  p-value: 0.01326\n\n\nLet’s plot the result. Try to change show_ci to TRUE. Does it explain the p-value now?\n\nggpredict(model_in, terms= c(\"n_individuals\", \"indep\")) %&gt;%\n  plot(show_ci = FALSE) +\n  labs(title = \"Regression with Interaction Term\",\n       x = \"Number of Individuals in a Cabinet\",\n       y = \"Perception of Corruption\",\n       color = \"Leader's Status\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nAnd you can easily simulate the data (i.e., calculate the marginal effect) using ggpredict(). For example,\n\nggpredict(model_in, terms= c(\"n_individuals [12]\", \"indep [Independent]\"))\n\n# Predicted values of Perceptions_of_corruption\n\nn_individuals | Predicted |     95% CI\n--------------------------------------\n           12 |      0.89 | 0.71, 1.07"
  },
  {
    "objectID": "ps405-d_3.html#using-dummy-variables-in-the-regression",
    "href": "ps405-d_3.html#using-dummy-variables-in-the-regression",
    "title": "Multiple Linear Regression",
    "section": "Using dummy variables in the regression",
    "text": "Using dummy variables in the regression\nToday we are working with WhoGov dataset. As usual, I recomment taking a look at their codebook.\n\nwhogov = read.csv(\"data/WhoGov.csv\")\n\nFirst of all, these are the following variables we are going to work with today:\n\ncountry_name is a country name\nn_individuals number of unique persons in the cabinet\nleaderexperience_continuous the number of years the person has been leader of the country in total.\nleader_party party of the leader\nsystem_category the regime type\n\nStart with exploring the distribution of number of unique persons in the cabinet (n_individuals)\n\nggplot(whogov) +\n  geom_histogram(aes(x = n_individuals)) \n\n\n\n\n\n\n\n\nPresent the descriptive statistics of n_individuals variable.\n\n...\n\nLet’s explore whether a leader of a country being independent from a party leads to more or fewer people in their cabinet. First, let’s create a dummy variable indicating if a leader is independent or non-independent. You can use 1 or 0 instead, but to make it more readable we stick to more transparent labels.\n\nwhogov = whogov %&gt;%\n  mutate(indep = ifelse(leader_party == \"independent\", \"Independent\", \"Non-independent\"))\n\nNow, build a simple model and explore the effect.\n\nlm(n_individuals ~ indep, whogov) %&gt;%\n  summary()\n\n\nCall:\nlm(formula = n_individuals ~ indep, data = whogov)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.342  -7.342  -2.342   5.658 106.658 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           24.0592     0.2761  87.148   &lt;2e-16 ***\nindepNon-independent   2.2833     0.3058   7.466    9e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.35 on 9127 degrees of freedom\n  (24 пропущенных наблюдений удалены)\nMultiple R-squared:  0.006071,  Adjusted R-squared:  0.005962 \nF-statistic: 55.75 on 1 and 9127 DF,  p-value: 9.003e-14\n\n\nWhat if we want to relevel the indep variable to know the effect relative to Non-independent leader?\n\nwhogov$indep = relevel(whogov$indep, ref = \"Non-independent\")\n\nOops! This is why classes of data are important. Fix it!\n\nwhogov$indep = as.factor(whogov$indep)\n\nNow we can relevel the variable\n\nwhogov$indep = relevel(whogov$indep, ref = \"Non-independent\")\n\nCompare the models. Does the result sound reasonable? Pretty much. This is simply an inverse. But things get way more interesting if categorical variable has more than 2 levels. You will see this later on. For now, let’s interpret the result.\n\nlm(n_individuals ~ indep, whogov) %&gt;%\n  summary()\n\n\nCall:\nlm(formula = n_individuals ~ indep, data = whogov)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.342  -7.342  -2.342   5.658 106.658 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       26.3425     0.1315 200.264   &lt;2e-16 ***\nindepIndependent  -2.2833     0.3058  -7.466    9e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.35 on 9127 degrees of freedom\n  (24 пропущенных наблюдений удалены)\nMultiple R-squared:  0.006071,  Adjusted R-squared:  0.005962 \nF-statistic: 55.75 on 1 and 9127 DF,  p-value: 9.003e-14"
  },
  {
    "objectID": "ps405-d_3.html#dummy-variables-and-ols-regression",
    "href": "ps405-d_3.html#dummy-variables-and-ols-regression",
    "title": "Multiple Linear Regression",
    "section": "Dummy variables and OLS regression",
    "text": "Dummy variables and OLS regression\nToday we are working with WhoGov dataset. As usual, I recomment taking a look at their codebook.\n\nwhogov = read.csv(\"data/WhoGov.csv\")\n\nFirst of all, these are the following variables we are going to work with today:\n\ncountry_name is a country name\nn_individuals number of unique persons in the cabinet\nleaderexperience_continuous the number of years the person has been leader of the country in total.\nleader_party party of the leader\n\nStart with exploring the distribution of number of unique persons in the cabinet (n_individuals)\n\nggplot(whogov) +\n  geom_histogram(aes(x = n_individuals)) \n\n\n\n\n\n\n\n\nPresent the descriptive statistics of n_individuals variable.\n\n...\n\nLet’s examine whether a country’s leader being independent from a political party is associated with having more or fewer members in their cabinet. First, let’s create a dummy variable indicating if a leader is independent or non-independent. You can use 1 or 0 instead, but to make it more readable here we stick to more transparent labels.\n\nwhogov = whogov %&gt;%\n  mutate(indep = ifelse(leader_party == \"independent\", \"Independent\", \"Non-independent\"))\n\nNow, build a simple model and explore the effect. On average, being a non-independent (i.e. partisan) leader is associated with having 2.28 more members in their cabinet compared to independent leaders.\n\nlm(n_individuals ~ indep, whogov) %&gt;%\n  summary()\n\n\nCall:\nlm(formula = n_individuals ~ indep, data = whogov)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.342  -7.342  -2.342   5.658 106.658 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           24.0592     0.2761  87.148   &lt;2e-16 ***\nindepNon-independent   2.2833     0.3058   7.466    9e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.35 on 9127 degrees of freedom\n  (24 observations deleted due to missingness)\nMultiple R-squared:  0.006071,  Adjusted R-squared:  0.005962 \nF-statistic: 55.75 on 1 and 9127 DF,  p-value: 9.003e-14\n\n\nWhat if we want to know the effect relative to Non-independent leader? Let’s relevel() the variable!\n\nwhogov$indep = relevel(whogov$indep, ref = \"Non-independent\")\n\nOops! This is why classes of data are important. Fix it!\n\nwhogov$indep = as.factor(whogov$indep)\n\nNow we can relevel the variable\n\nwhogov$indep = relevel(whogov$indep, ref = \"Non-independent\")\n\nCompare the models. Does the result sound reasonable? Pretty much. This is simply an inverse. But things get way more interesting if a categorical variable has more than 2 levels. You will see this later on.\n\nlm(n_individuals ~ indep, whogov) %&gt;%\n  summary()\n\n\nCall:\nlm(formula = n_individuals ~ indep, data = whogov)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.342  -7.342  -2.342   5.658 106.658 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       26.3425     0.1315 200.264   &lt;2e-16 ***\nindepIndependent  -2.2833     0.3058  -7.466    9e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.35 on 9127 degrees of freedom\n  (24 observations deleted due to missingness)\nMultiple R-squared:  0.006071,  Adjusted R-squared:  0.005962 \nF-statistic: 55.75 on 1 and 9127 DF,  p-value: 9.003e-14"
  },
  {
    "objectID": "index.html#grade-increase-policy",
    "href": "index.html#grade-increase-policy",
    "title": "PS405 Linear Models",
    "section": "Grade increase policy",
    "text": "Grade increase policy\nTo improve your homework grade, you should submit the exercises from the corresponding lab session held during the week the homework was assigned. For instance, if you wish to improve the grade for the first homework, which was assigned on January 16th, you should submit the completed exercises from the second lab, which took place on the same day. If you prefer not to check the dates each time, given that homework is assigned each week starting from week 2, you can use the formula:\n\\[\n\\text{E}[\\text{Lab Number}|\\text{Pset is assigned each week}] = \\text{Pset Number} + 1\n\\]"
  },
  {
    "objectID": "index.html#pset-grade-increase-policy",
    "href": "index.html#pset-grade-increase-policy",
    "title": "PS405 Linear Models",
    "section": "Pset Grade Increase Policy",
    "text": "Pset Grade Increase Policy\nTo improve your grade for the problem set, you should submit the exercises from the corresponding lab session held during the week the homework was assigned. Exercises can be found at the end of each lab. You can increase grades for every problem set, except for the last one before the final. The maximum possible increase is two points.\nFor instance, if you wish to improve the grade for the first homework, which was assigned on January 16th, you should submit the completed exercises from the second lab, which took place on the same day. If you prefer not to check the dates each time, given that homework is assigned each week starting from week 2, you can use the formula:\n\\[\n\\text{Lab Number}|\\text{Pset is assigned each week} = \\text{Pset Number} + 1\n\\]\nAfter the grades are released, you have one week to submit the .qmd file via email to artur.baranov@u.northwestern.edu."
  },
  {
    "objectID": "ps405-d_4.html",
    "href": "ps405-d_4.html",
    "title": "Review and Confidence Intervals",
    "section": "",
    "text": "Congrats passing through the first quiz! How are you feeling?\nGrades for the psets are out.\n\n\nDownload script\n\n\n\nDownload data"
  },
  {
    "objectID": "ps405-d_4.html#latex-issues",
    "href": "ps405-d_4.html#latex-issues",
    "title": "Review and Confidence Intervals",
    "section": "\\(\\LaTeX\\) issues",
    "text": "\\(\\LaTeX\\) issues\nIntegration of R, Python, markdown, Latex and other useful languages incredibly useful. But it comes to a price that researchers should be careful. Any \\(\\LaTeX\\) code should go within two $ dollar signs $. For example, an inline formula looks like this: $ Y = 10 $, which produces the following result: \\(Y = 10\\). Alternatively, you can use a double dollar sign to start a “chunk” for latex. For example:\n\\[\nY = \\beta_0 + \\beta_1X + u\n\\]"
  },
  {
    "objectID": "ps405-d_4.html#useful-functions",
    "href": "ps405-d_4.html#useful-functions",
    "title": "Review and Confidence Intervals",
    "section": "Useful functions",
    "text": "Useful functions\nSometimes you might want to visualize some mathematical functions using geom_function(). In the HW, you were asked to plot an OLS regression vs the true data generating process. For this purpose example below is super useful (however, geom_abline() for this particular task is perfect, too).\n\nset.seed(123)\n\nexample_data = data.frame(x = rnorm(100,\n                                    mean = 2,\n                                    sd = 15),\n                          y = rnorm(100,\n                                    mean = 2,\n                                    sd = 15) * rnorm(100))\n\nggplot(example_data, aes(x = x, y = y)) +\n  geom_point() +\n  geom_smooth(aes(color = \"Fitted\"), method = \"lm\", se = F) +\n  geom_function(aes(color = \"Known\"), fun = function(x){1 + 0.5 * x}, size = 1.2) \n\n\n\n\n\n\n\n\nSometimes it’s useful to visualize, say, polynomials! How does \\(x^3\\) look like?\n\nggplot() +\n  geom_function(fun = function(x){x^2}) +\n  geom_vline(xintercept = 0) +\n  xlim(-1, 1)"
  },
  {
    "objectID": "ps405-d_4.html#fixed-effects",
    "href": "ps405-d_4.html#fixed-effects",
    "title": "Review and Confidence Intervals",
    "section": "Fixed Effects",
    "text": "Fixed Effects\nWhen we introduce a dummy variable into the model, we quite often are interested in controlling for unobserved heterogeneity by allowing each category to have its own intercept. This is referred to as fixed effects.\nFirst, let’s create a dummy variable indicating if a leader is independent or Partisan. You can use 1 or 0 instead, but to make it more readable here we stick to more transparent labels.\n\nwhogov = whogov %&gt;%\n  mutate(indep = ifelse(leader_party == \"independent\", \"Independent\", \"Partisan\"))\n\nDon’t forget about the class of the variable!\n\nwhogov$indep = as.factor(whogov$indep)\n\nTake a moment to think about what unobserved heterogeneity we can control for by including whether a leader is independent or partisan in the model.\n\nmodel_fe = lm(n_individuals ~ leaderexperience_continuous + indep, whogov) \nsummary(model_fe)\n\n\nCall:\nlm(formula = n_individuals ~ leaderexperience_continuous + indep, \n    data = whogov)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.437  -7.078  -1.796   5.377 108.632 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 20.98188    0.30295   69.26   &lt;2e-16 ***\nleaderexperience_continuous  0.35700    0.01617   22.08   &lt;2e-16 ***\nindepPartisan                3.02909    0.29988   10.10   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.06 on 9126 degrees of freedom\n  (24 observations deleted due to missingness)\nMultiple R-squared:  0.05649,   Adjusted R-squared:  0.05628 \nF-statistic: 273.2 on 2 and 9126 DF,  p-value: &lt; 2.2e-16\n\n\nLet’s relevel to get the results for Independent candidates.\n\nwhogov$indep = relevel(whogov$indep, ref = \"Partisan\")\nmodel_fe = lm(n_individuals ~ leaderexperience_continuous + indep, whogov) \nsummary(model_fe)\n\n\nCall:\nlm(formula = n_individuals ~ leaderexperience_continuous + indep, \n    data = whogov)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.437  -7.078  -1.796   5.377 108.632 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 24.01096    0.16605  144.60   &lt;2e-16 ***\nleaderexperience_continuous  0.35700    0.01617   22.08   &lt;2e-16 ***\nindepIndependent            -3.02909    0.29988  -10.10   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.06 on 9126 degrees of freedom\n  (24 observations deleted due to missingness)\nMultiple R-squared:  0.05649,   Adjusted R-squared:  0.05628 \nF-statistic: 273.2 on 2 and 9126 DF,  p-value: &lt; 2.2e-16\n\n\nTo understand what’s going on in the model we might want to visualize the result. Load the ggeffects library.\n\nlibrary(ggeffects)\n\nThen, visualize the result. What can we see?\n\nggpredict(model_fe, terms = c(\"leaderexperience_continuous\", \"indep\")) %&gt;%\n  plot() +\n  labs(title = \"Fixed Effects Regression\",\n       x = \"Tenure of a Leader\",\n       y = \"Number of Individuals in a Cabinet\",\n       color = \"Leader's Status\") +\n  theme_bw()"
  },
  {
    "objectID": "ps405-d_4.html#interactions",
    "href": "ps405-d_4.html#interactions",
    "title": "Review and Confidence Intervals",
    "section": "Interactions",
    "text": "Interactions\nOften dummy variables are used to introduce an interaction term in the model. We will explore the association between Perceptions_of_corruption and number of people in the cabinet (n_individuals) depending on the independence of the party leader.\nThe task isn’t trivial as now we planning to use data from two datasets, Let’s subset those.\n\nwhr_subset = whr %&gt;%\n  select(Country_name, Perceptions_of_corruption)\n\nwhogov_subset = whogov %&gt;%\n  filter(year == 2021) %&gt;%\n  select(country_name, n_individuals, indep)\n\nNow, we are merging them. Once again, there is a great resource for joins (check “the {dplyr} way”)!\n\nwhr_whogov = whr_subset %&gt;%\n  left_join(whogov_subset, by = c(\"Country_name\" = \"country_name\")) \n\nCheck the result of the left_join()\n\nhead(whr_whogov)\n\n  Country_name Perceptions_of_corruption n_individuals    indep\n1      Finland                     0.182            23 Partisan\n2      Denmark                     0.196            24 Partisan\n3      Iceland                     0.668            15 Partisan\n4       Israel                     0.708            33 Partisan\n5  Netherlands                     0.379            18 Partisan\n6       Sweden                     0.202            26 Partisan\n\n\nNow, let’s interact the variable\n\nmodel_in = lm(Perceptions_of_corruption ~ n_individuals * indep, whr_whogov)\nsummary(model_in)\n\n\nCall:\nlm(formula = Perceptions_of_corruption ~ n_individuals * indep, \n    data = whr_whogov)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.54000 -0.05737  0.04300  0.10864  0.24382 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                     0.575192   0.061646   9.331 5.59e-16 ***\nn_individuals                   0.004818   0.002151   2.240   0.0269 *  \nindepIndependent                0.386220   0.159570   2.420   0.0170 *  \nn_individuals:indepIndependent -0.010703   0.005501  -1.946   0.0540 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1737 on 123 degrees of freedom\n  (10 observations deleted due to missingness)\nMultiple R-squared:  0.08324,   Adjusted R-squared:  0.06088 \nF-statistic: 3.723 on 3 and 123 DF,  p-value: 0.01326\n\n\nLet’s plot the result.\n\nggpredict(model_in, terms= c(\"n_individuals\", \"indep\")) %&gt;%\n  plot(show_ci = FALSE) +\n  labs(title = \"Regression with Interaction Term\",\n       x = \"Number of Individuals in a Cabinet\",\n       y = \"Perception of Corruption\",\n       color = \"Leader's Status\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nI guess after solving pset and quiz you realize why interpreting interactions is hard? You can easily simulate the data (i.e., calculate the marginal effect) using ggpredict(). For example,\n\nggpredict(model_in, terms= c(\"n_individuals [12]\", \"indep [Independent]\"))\n\n# Predicted values of Perceptions_of_corruption\n\nn_individuals | Predicted |     95% CI\n--------------------------------------\n           12 |      0.89 | 0.71, 1.07"
  },
  {
    "objectID": "ps405-d_4.html#transformations",
    "href": "ps405-d_4.html#transformations",
    "title": "Confidence Intervals and Hypothesis Testing",
    "section": "Transformations",
    "text": "Transformations"
  },
  {
    "objectID": "ps405-d_4.html#iv-transformations",
    "href": "ps405-d_4.html#iv-transformations",
    "title": "Review and Confidence Intervals",
    "section": "IV Transformations",
    "text": "IV Transformations\nOne of the assumptions for OLS is that there is a linear relationship between the dependent and independent variables. However, this quite often not the case. Let’s reverse the correction made in World Happiness report data. See below. Does it look linear?\n\nggplot(whr) +\n  geom_point(aes(x = exp(Logged_GDP_per_capita), y = Ladder_score)) +\n  labs(x = \"GDP per capita\")\n\n\n\n\n\n\n\n\nIt doesn’t. It’s hard to describe this relationship in a linear manner. Natural log would explain this better, right?\n\nggplot(whr, aes(x = exp(Logged_GDP_per_capita), y = Ladder_score)) +\n  geom_point() +\n  geom_function(fun = function(x){log(x) - 4}) +\n  labs(x = \"GDP per capita\")\n\n\n\n\n\n\n\n\nThis is why we use the natural logarithm to transform GDP per capita. The transformation reveals a linear relationship between the two variables, allowing us to capture non-linear patterns in a linear format when using OLS regression. Another commonly used transformation is quadratic (\\(x^2\\)), which serves the same purpose of addressing non-linear relationships. We call latter ones polynomials.\n\nggplot(whr, aes(x = Logged_GDP_per_capita, y = Ladder_score)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "data_process.html",
    "href": "data_process.html",
    "title": "Untitled",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nsipri = read.csv(\"import-export-values_1950-2024.csv\")\nsipri = sipri %&gt;%\n  select(-X2024)\n\n\nsipri = sipri %&gt;%\n  pivot_longer(2:75,\n               names_to = \"Year\",\n               values_to = \"Import\")\n\nsipri = sipri %&gt;%\n  mutate(Year = str_remove(Year, \"X\"))\n\nsipri = na.omit(sipri)\n\n\nload(url(\"https://github.com/vdeminstitute/vdemdata/raw/6bee8e170578fe8ccdc1414ae239c5e870996bc0/data/vdem.RData\"))\n\ne_v2x_polyarchy_5C\n\nvdem_sub = vdem %&gt;%\n  select(year, country_name, e_v2x_polyarchy_4C)\n\nvdem_sub$year = as.character(vdem_sub$year)\n\nmerger = sipri %&gt;%\n  left_join(vdem_sub, by = c('Year' = 'year', 'Recipient' = 'country_name'))\n\nmerger = na.omit(merger)\n\nmerger = merger %&gt;%\n  mutate(Regime = case_when(e_v2x_polyarchy_4C == 0 ~ \"Autocratic\",\n                            e_v2x_polyarchy_4C == 0.333 ~ \"Electoral Authoritarian\",\n                            e_v2x_polyarchy_4C == 0.667 ~ \"Minimally Democratic\",\n                            e_v2x_polyarchy_4C == 1 ~ \"Democratic\"))\n\nmerger = merger %&gt;%\n  select(-e_v2x_polyarchy_4C)\n\n# write.csv(merger, \"sipri.csv\", row.names = F)"
  },
  {
    "objectID": "ps405-d_5.html",
    "href": "ps405-d_5.html",
    "title": "Presenting Results of Regression",
    "section": "",
    "text": "Any questions?\n\n\nDownload script\n\n\n\nDownload data"
  },
  {
    "objectID": "ps405-d_5.html#tables",
    "href": "ps405-d_5.html#tables",
    "title": "Presenting Results of Regression",
    "section": "Tables",
    "text": "Tables\nThe most common way to present the resutls of the regression is in tables. We have practiced it over the last two quarters. By now, the expectation is you know how to present models in a “publishable” way. For details and examples see details.\nDon’t forget to:\n\nInclude p-values and \\(\\alpha\\) (critical values for stars display)!\nInclude standad errors or confidence intervals for \\(\\beta\\)\nIf you have a categorical variable, mention the reference category\n\\(R^2\\) for simple linear regression and \\(R^2_a\\) for multiple linear regression\nInclude number of observations\n\nAdd the following argument: output = \"table.html\".\n\nlibrary(modelsummary)\npublishable_table = modelsummary(list(\"Base model\" = model_basic,\n                    \"Fixed Effects model\" = model_fe,\n                    \"Interaction model\" = model_int),\n                   title = \"Arms Import Models\",  \n                   stars = TRUE,\n                   gof_omit = \"AIC|BIC|Log.Lik|F|RMSE\",\n                   coef_rename = c(\"(Intercept)\", \n                             \"Log GDP\", \n                             \"International Conflict\", \n                             \"Regime: Democratic\",\n                             \"Regime: Electoral Authoritarian\",\n                             \"Regime: Minimally Democratic\",\n                             \"Log GDP × International Conflict\"),\n                   notes = \"Regime reference category: Autocratic\")\n\npublishable_table\n\n\n\n    \n\n    \n    \n      \n        \n        Arms Import Models\n              \n                 \n                Base model\n                Fixed Effects model\n                Interaction model\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\nRegime reference category: Autocratic\n        \n                \n                  (Intercept)\n                  -718.034***\n                  -783.055***\n                  -747.804***\n                \n                \n                  \n                  (29.032)\n                  (36.852)\n                  (37.877)\n                \n                \n                  Log GDP\n                  108.547***\n                  126.364***\n                  122.263***\n                \n                \n                  \n                  (3.168)\n                  (4.468)\n                  (4.582)\n                \n                \n                  International Conflict\n                  \n                  206.923***\n                  -375.723*\n                \n                \n                  \n                  \n                  (26.470)\n                  (151.132)\n                \n                \n                  Regime: Democratic\n                  \n                  -95.328***\n                  -95.161***\n                \n                \n                  \n                  \n                  (17.191)\n                  (17.162)\n                \n                \n                  Regime: Electoral Authoritarian\n                  \n                  -151.434***\n                  -151.842***\n                \n                \n                  \n                  \n                  (23.328)\n                  (23.290)\n                \n                \n                  Regime: Minimally Democratic\n                  \n                  -216.183***\n                  -218.460***\n                \n                \n                  \n                  \n                  (50.820)\n                  (50.740)\n                \n                \n                  Log GDP × International Conflict\n                  \n                  \n                  63.002***\n                \n                \n                  \n                  \n                  \n                  (16.090)\n                \n                \n                  Num.Obs.\n                  6441\n                  4353\n                  4353\n                \n                \n                  R2\n                  0.154\n                  0.199\n                  0.202\n                \n                \n                  R2 Adj.\n                  0.154\n                  0.199\n                  0.201\n                \n        \n      \n    \n\n\n\nThe more complex the model, the harder it is to interpret the results. Let’s write out our models. You can often see these in articles. By plugging the coefficients we or our readers can calculate the predicted value for any GDP value, regime type and presence or absence of international conflict.\nThe basic model is easy, right?\n\\[\n\\text{Arms Import} = \\beta_0 + \\beta_1(\\text{LogGDP})\n\\] Now, fixed effects. It gets slightly trickier.\n\\[\n\\text{Arms Import} = \\beta_0 + \\beta_1(\\text{LogGDP}) + \\beta_2(\\text{International Conflict}) + \\beta_3(\\text{Regime})\n\\]\nAnd finally, interaction model. You can try to interpret the interaction, but we need to know the reference categories. Which is a bit of a hustle.\n\\[\n\\text{Arms Import} = \\beta_0 + \\beta_1(\\text{LogGDP}) + \\beta_2(\\text{International Conflict}) + \\beta_3(\\text{Regime}) + \\beta_4(\\text{LogGDP} \\times \\text{International Conflict})\n\\]"
  },
  {
    "objectID": "ps405-d_5.html#statistical-significante-and-magnitude-of-beta",
    "href": "ps405-d_5.html#statistical-significante-and-magnitude-of-beta",
    "title": "Presenting Results of Regression",
    "section": "Statistical Significante and Magnitude of \\(\\beta\\)",
    "text": "Statistical Significante and Magnitude of \\(\\beta\\)\nYou, probably, remember this from the problem sets. For yourself and reader it’s easier to compare effects visually.\nTo extract additional information automatically from the model, we use tidy() function from broom library. Take a moment to compare to “native” output.\n\nlibrary(broom)\nsummary(model_int)\n\n\nCall:\nlm(formula = Import ~ Log_GDP * International_conflict + Regime, \n    data = sipri_vdem)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1183.9  -214.6   -83.1    77.6  5177.3 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                     -747.804     37.877 -19.743  &lt; 2e-16 ***\nLog_GDP                          122.263      4.582  26.682  &lt; 2e-16 ***\nInternational_conflict1         -375.723    151.132  -2.486    0.013 *  \nRegimeDemocratic                 -95.161     17.162  -5.545 3.12e-08 ***\nRegimeElectoral Authoritarian   -151.842     23.290  -6.520 7.85e-11 ***\nRegimeMinimally Democratic      -218.460     50.740  -4.305 1.70e-05 ***\nLog_GDP:International_conflict1   63.002     16.090   3.916 9.16e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 453.8 on 4346 degrees of freedom\n  (2524 observations deleted due to missingness)\nMultiple R-squared:  0.2023,    Adjusted R-squared:  0.2012 \nF-statistic: 183.7 on 6 and 4346 DF,  p-value: &lt; 2.2e-16\n\n\nThis pretty much the dataframe with the regression output. Thus, it simplifies our work for visualization purposes! (and similar functionality is available in modelsummary library with get_estimates() command)\n\nmodel_int_output = tidy(model_int, conf.int = TRUE, conf.level = 0.95)\nmodel_int_output\n\n# A tibble: 7 × 7\n  term                 estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;                   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)            -748.      37.9     -19.7  3.69e- 83   -822.     -674. \n2 Log_GDP                 122.       4.58     26.7  2.19e-145    113.      131. \n3 International_confl…   -376.     151.       -2.49 1.30e-  2   -672.      -79.4\n4 RegimeDemocratic        -95.2     17.2      -5.54 3.12e-  8   -129.      -61.5\n5 RegimeElectoral Aut…   -152.      23.3      -6.52 7.85e- 11   -198.     -106. \n6 RegimeMinimally Dem…   -218.      50.7      -4.31 1.70e-  5   -318.     -119. \n7 Log_GDP:Internation…     63.0     16.1       3.92 9.16e-  5     31.5      94.5\n\n\nPlotting the effects is great to provide intuition about the significance and the magnitude of the effects. But! Don’t forget about the scales! Are you comparing comparable? Scaling may be helpful: how can you compare one unit increase in Log_GDP to “one unit increase” in International_conflict?\nMoreover, you cannot interpret the effect of International_conflict or Log_GDP without accounting for the interaction term. In our case, this plot is not publishible and is quite misleading. But in the exercises you’ll create a publishable plot for the fixed effects model.\n\nggplot(model_int_output) +\n  geom_linerange(aes(x = term,\n                    y = estimate,\n                    ymin = conf.low,\n                    ymax = conf.high)) +\n  geom_point(aes(x = term,\n                 y = estimate)) +\n  geom_hline(yintercept = 0, lty=2, color=\"gray\") +\n  coord_flip()"
  },
  {
    "objectID": "ps405-d_5.html#report-predicted-values",
    "href": "ps405-d_5.html#report-predicted-values",
    "title": "Presenting Results of Regression",
    "section": "Report predicted values",
    "text": "Report predicted values\nFor example, we take the most typical GDP, and calculate the effects for two categorical variables: International_conflict and Regime.\n\nggpredict(model_int, terms = c(\"International_conflict\", \"Regime\")) \n\n# Predicted values of Import\n\nRegime: Autocratic\n\nInternational_conflict | Predicted |         95% CI\n---------------------------------------------------\n0                      |    308.57 | 288.87, 328.27\n1                      |    477.20 | 423.80, 530.59\n\nRegime: Democratic\n\nInternational_conflict | Predicted |         95% CI\n---------------------------------------------------\n0                      |    213.41 | 187.75, 239.07\n1                      |    382.03 | 322.22, 441.85\n\nRegime: Electoral Authoritarian\n\nInternational_conflict | Predicted |         95% CI\n---------------------------------------------------\n0                      |    156.73 | 114.75, 198.70\n1                      |    325.35 | 258.22, 392.48\n\nRegime: Minimally Democratic\n\nInternational_conflict | Predicted |         95% CI\n---------------------------------------------------\n0                      |     90.11 |  -7.60, 187.82\n1                      |    258.74 | 146.76, 370.71\n\nAdjusted for:\n* Log_GDP = 8.64\n\n\nLet’s make it look publishable. We wrangle the data a bit. By now, the code shouldn’t stress you out.\n\nmodel_int_groupped = ggpredict(model_int, terms = c(\"International_conflict\", \"Regime\")) %&gt;%\n  as.data.frame() %&gt;%\n  rename(International_conflict = x,\n         Regime = group,\n         Import = predicted) \n\nmodel_int_groupped\n\n  International_conflict    Import std.error   conf.low conf.high\n1                      0 308.56877  10.04954 288.866542  328.2710\n2                      0 213.40769  13.08769 187.749148  239.0662\n3                      0 156.72724  21.40898 114.754718  198.6998\n4                      0  90.10883  49.84073  -7.604411  187.8221\n5                      1 477.19551  27.23333 423.804293  530.5867\n6                      1 382.03443  30.51067 322.217952  441.8509\n7                      1 325.35398  34.24112 258.223927  392.4840\n8                      1 258.73557  57.11487 146.761296  370.7098\n                   Regime\n1              Autocratic\n2              Democratic\n3 Electoral Authoritarian\n4    Minimally Democratic\n5              Autocratic\n6              Democratic\n7 Electoral Authoritarian\n8    Minimally Democratic\n\n\nFinally, present the marginal effects using tinytable.1 The code below is quite messy, in your free time you can explore it in a more detail. For now, I want this code to be available to you. Add this line of code in the end: save_tt(\"predicted_values.html\")\n\nlibrary(tinytable)\n\nmodel_int_groupped %&gt;%\n  group_by(International_conflict, Regime) %&gt;%\n  summarize(Import = paste0(round(Import, 3), \"\\n\", \"[\", round(conf.low, 3), \"; \", round(conf.high, 3), \"]\")) %&gt;%\n  pivot_wider(names_from = Regime,\n              values_from = Import) %&gt;%\n  mutate(International_conflict = ifelse(International_conflict == 1, \"Present\", \"Absent\")) %&gt;%\n  rename(`International Conflict` = International_conflict) %&gt;% \n  tt(note = \"Adjusted for average log of GDP (=8.64)\") %&gt;%\n  group_tt(j = list(\"Regime\" = 2:5)) \n\n`summarise()` has grouped output by 'International_conflict'. You can override\nusing the `.groups` argument.\n\n\n\n\n    \n\n    \n    \n      \n        \n\n \nRegime\n\n        \n              \n                International Conflict\n                Autocratic\n                Democratic\n                Electoral Authoritarian\n                Minimally Democratic\n              \n        \n        Adjusted for average log of GDP (=8.64)\n        \n                \n                  Absent \n                  308.569\n[288.867; 328.271]\n                  213.408\n[187.749; 239.066]\n                  156.727\n[114.755; 198.7]  \n                  90.109\n[-7.604; 187.822] \n                \n                \n                  Present\n                  477.196\n[423.804; 530.587]\n                  382.034\n[322.218; 441.851]\n                  325.354\n[258.224; 392.484]\n                  258.736\n[146.761; 370.71]\n                \n        \n      \n    \n\n\n\nWhy voters who value democracy participate in democratic backsliding: 8"
  },
  {
    "objectID": "ps405-d_5.html#footnotes",
    "href": "ps405-d_5.html#footnotes",
    "title": "Presenting Results of Regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nGreat example of research presenting the results in a similar manner can be found in Reuter, O.J. and Szakonyi, D., 2015. Online social media and political awareness in authoritarian regimes. British Journal of Political Science, 45(1), pp.29-51.↩︎"
  },
  {
    "objectID": "ps405-d_5.html#statistical-significance-and-magnitude-of-beta",
    "href": "ps405-d_5.html#statistical-significance-and-magnitude-of-beta",
    "title": "Presenting Results of Regression",
    "section": "Statistical Significance and Magnitude of \\(\\beta\\)",
    "text": "Statistical Significance and Magnitude of \\(\\beta\\)\nYou, probably, remember this from the problem sets. For yourself and reader it’s easier to compare effects visually.\nTo extract additional information automatically from the model, we use tidy() function from broom library. Take a moment to compare to “native” output.\n\nlibrary(broom)\nsummary(model_int)\n\n\nCall:\nlm(formula = Import ~ Log_GDP * International_conflict + Regime, \n    data = sipri_vdem)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1183.9  -214.6   -83.1    77.6  5177.3 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                     -747.804     37.877 -19.743  &lt; 2e-16 ***\nLog_GDP                          122.263      4.582  26.682  &lt; 2e-16 ***\nInternational_conflict1         -375.723    151.132  -2.486    0.013 *  \nRegimeDemocratic                 -95.161     17.162  -5.545 3.12e-08 ***\nRegimeElectoral Authoritarian   -151.842     23.290  -6.520 7.85e-11 ***\nRegimeMinimally Democratic      -218.460     50.740  -4.305 1.70e-05 ***\nLog_GDP:International_conflict1   63.002     16.090   3.916 9.16e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 453.8 on 4346 degrees of freedom\n  (2524 observations deleted due to missingness)\nMultiple R-squared:  0.2023,    Adjusted R-squared:  0.2012 \nF-statistic: 183.7 on 6 and 4346 DF,  p-value: &lt; 2.2e-16\n\n\nThis pretty much the dataframe with the regression output. Thus, it simplifies our work for visualization purposes! (and similar functionality is available in modelsummary library with get_estimates() command)\n\nmodel_int_output = tidy(model_int, conf.int = TRUE, conf.level = 0.95)\nmodel_int_output\n\n# A tibble: 7 × 7\n  term                 estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;                   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)            -748.      37.9     -19.7  3.69e- 83   -822.     -674. \n2 Log_GDP                 122.       4.58     26.7  2.19e-145    113.      131. \n3 International_confl…   -376.     151.       -2.49 1.30e-  2   -672.      -79.4\n4 RegimeDemocratic        -95.2     17.2      -5.54 3.12e-  8   -129.      -61.5\n5 RegimeElectoral Aut…   -152.      23.3      -6.52 7.85e- 11   -198.     -106. \n6 RegimeMinimally Dem…   -218.      50.7      -4.31 1.70e-  5   -318.     -119. \n7 Log_GDP:Internation…     63.0     16.1       3.92 9.16e-  5     31.5      94.5\n\n\nPlotting the effects is great to provide intuition about the significance and the magnitude of the effects. But! Don’t forget about the scales! Are you comparing comparable? Scaling may be helpful: how can you compare one unit increase in Log_GDP to “one unit increase” in International_conflict?\nMoreover, you cannot interpret the effect of International_conflict or Log_GDP without accounting for the interaction term. In our case, this plot is not publishible and is quite misleading. It is more suitable for fixed effects and simple additive models. However, don’t forget about the scale!\n\nggplot(model_int_output) +\n  geom_linerange(aes(x = term,\n                    y = estimate,\n                    ymin = conf.low,\n                    ymax = conf.high)) +\n  geom_point(aes(x = term,\n                 y = estimate)) +\n  geom_hline(yintercept = 0, lty=2, color=\"gray\") +\n  coord_flip()"
  },
  {
    "objectID": "ps405-d_5.html#predicted-values",
    "href": "ps405-d_5.html#predicted-values",
    "title": "Presenting Results of Regression",
    "section": "Predicted values",
    "text": "Predicted values\nPresenting predicted values provides the reader with intuition about what happens when variables take specific values. For example, we take the most typical GDP, and calculate the effects for two categorical variables: International_conflict and Regime.\n\nggpredict(model_int, terms = c(\"International_conflict\", \"Regime\")) \n\n# Predicted values of Import\n\nRegime: Autocratic\n\nInternational_conflict | Predicted |         95% CI\n---------------------------------------------------\n0                      |    308.57 | 288.87, 328.27\n1                      |    477.20 | 423.80, 530.59\n\nRegime: Democratic\n\nInternational_conflict | Predicted |         95% CI\n---------------------------------------------------\n0                      |    213.41 | 187.75, 239.07\n1                      |    382.03 | 322.22, 441.85\n\nRegime: Electoral Authoritarian\n\nInternational_conflict | Predicted |         95% CI\n---------------------------------------------------\n0                      |    156.73 | 114.75, 198.70\n1                      |    325.35 | 258.22, 392.48\n\nRegime: Minimally Democratic\n\nInternational_conflict | Predicted |         95% CI\n---------------------------------------------------\n0                      |     90.11 |  -7.60, 187.82\n1                      |    258.74 | 146.76, 370.71\n\nAdjusted for:\n* Log_GDP = 8.64\n\n\nLet’s make it look publishable. We wrangle the data a bit. By now, the code shouldn’t stress you out. If it does, then run it step-by-step to get a sense of what’s going on!\n\nmodel_int_groupped = ggpredict(model_int, terms = c(\"International_conflict\", \"Regime\")) %&gt;%\n  as.data.frame() %&gt;%\n  rename(International_conflict = x,\n         Regime = group,\n         Import = predicted) \n\nmodel_int_groupped\n\n  International_conflict    Import std.error   conf.low conf.high\n1                      0 308.56877  10.04954 288.866542  328.2710\n2                      0 213.40769  13.08769 187.749148  239.0662\n3                      0 156.72724  21.40898 114.754718  198.6998\n4                      0  90.10883  49.84073  -7.604411  187.8221\n5                      1 477.19551  27.23333 423.804293  530.5867\n6                      1 382.03443  30.51067 322.217952  441.8509\n7                      1 325.35398  34.24112 258.223927  392.4840\n8                      1 258.73557  57.11487 146.761296  370.7098\n                   Regime\n1              Autocratic\n2              Democratic\n3 Electoral Authoritarian\n4    Minimally Democratic\n5              Autocratic\n6              Democratic\n7 Electoral Authoritarian\n8    Minimally Democratic\n\n\nFinally, present the marginal effects using tinytable.1 The code below is quite messy, in your free time you can explore it in a more detail. For now, I want this code to be available to you. Add this line of code in the end: save_tt(\"predicted_values.html\") to save the table on your machine.\n\nlibrary(tinytable)\n\nmodel_int_groupped %&gt;%\n  group_by(International_conflict, Regime) %&gt;%\n  summarize(Import = paste0(round(Import, 3), \"\\n\", \"[\", round(conf.low, 3), \"; \", round(conf.high, 3), \"]\")) %&gt;%\n  pivot_wider(names_from = Regime,\n              values_from = Import) %&gt;%\n  mutate(International_conflict = ifelse(International_conflict == 1, \"Present\", \"Absent\")) %&gt;%\n  rename(`International Conflict` = International_conflict) %&gt;% \n  tt(note = \"Adjusted for average log of GDP (=8.64)\") %&gt;%\n  group_tt(j = list(\"Regime\" = 2:5)) \n\n\n\n    \n\n    \n    \n      \n        \n\n \nRegime\n\n        \n              \n                International Conflict\n                Autocratic\n                Democratic\n                Electoral Authoritarian\n                Minimally Democratic\n              \n        \n        Adjusted for average log of GDP (=8.64)\n        \n                \n                  Absent\n                  308.569\n[288.867; 328.271]\n                  213.408\n[187.749; 239.066]\n                  156.727\n[114.755; 198.7]\n                  90.109\n[-7.604; 187.822]\n                \n                \n                  Present\n                  477.196\n[423.804; 530.587]\n                  382.034\n[322.218; 441.851]\n                  325.354\n[258.224; 392.484]\n                  258.736\n[146.761; 370.71]"
  },
  {
    "objectID": "ps405-d_5.html#reporting-marginal-effects",
    "href": "ps405-d_5.html#reporting-marginal-effects",
    "title": "Presenting Results of Regression",
    "section": "Reporting Marginal Effects",
    "text": "Reporting Marginal Effects\nCalculate the most “typical” observation (or simply the average observation) across all indepdenent variables.\n\ntypical_obs = sipri_vdem %&gt;%\n      summarize(Log_GDP = mean(Log_GDP, na.rm = T),\n                International_conflict = table(International_conflict) %&gt;% which.max() %&gt;% names(),\n                Regime = table(Regime) %&gt;% which.max() %&gt;% names())\n\ntypical_obs\n\n   Log_GDP International_conflict     Regime\n1 8.984952                      0 Autocratic\n\n\nThis would be our baseline.\n\nggpredict(model_int, typical_obs)\n\n# Predicted values of Import\n\nLog_GDP | Predicted |         95% CI\n------------------------------------\n   8.98 |    350.72 | 329.90, 371.54\n\n\nAnd now you can easily calculate the average marginal effect with one unit increase in some X.\n\nmarginal_effects = list(Log_GDP = c(8.984952, 8, 8.5, 9.5, 10),\n                        International_conflict = c(\"0\"),\n                        Regime = c(\"Autocratic\", \"Democratic\"))\n\n\nggpredict(model_int, marginal_effects) \n\n# Predicted values of Import\n\nRegime: Autocratic\n\nLog_GDP | Predicted |         95% CI\n------------------------------------\n   8.00 |    230.30 | 211.46, 249.13\n   8.50 |    291.43 | 272.06, 310.80\n   8.98 |    350.72 | 329.90, 371.54\n   9.50 |    413.69 | 390.51, 436.87\n  10.00 |    474.82 | 448.77, 500.88\n\nRegime: Democratic\n\nLog_GDP | Predicted |         95% CI\n------------------------------------\n   8.00 |    135.14 | 106.89, 163.38\n   8.50 |    196.27 | 170.13, 222.41\n   8.98 |    255.56 | 230.85, 280.27\n   9.50 |    318.53 | 294.54, 342.51\n  10.00 |    379.66 | 355.54, 403.78"
  },
  {
    "objectID": "ps405-d_5.html#marginal-effects",
    "href": "ps405-d_5.html#marginal-effects",
    "title": "Presenting Results of Regression",
    "section": "Marginal Effects",
    "text": "Marginal Effects\nCalculate the “typical” observation (or simply the average observation) across all indepdenent variables.\n\ntypical_obs = sipri_vdem %&gt;%\n      summarize(Log_GDP = mean(Log_GDP, na.rm = T),\n                International_conflict = table(International_conflict) %&gt;% which.max() %&gt;% names(),\n                Regime = table(Regime) %&gt;% which.max() %&gt;% names())\n\ntypical_obs\n\n   Log_GDP International_conflict     Regime\n1 8.984952                      0 Autocratic\n\n\nThis would be our baseline. We can calculate the predicted value for the typical observation.\n\nggpredict(model_int, typical_obs)\n\n# Predicted values of Import\n\nLog_GDP | Predicted |         95% CI\n------------------------------------\n   8.98 |    350.72 | 329.90, 371.54\n\n\nHowever, the most interesting is to know how the DV change if the IV changes (holding everything else constant). Basically, we are trying to get a simple intepreation, as it is with the simple additive OLS. You can easily calculate the average marginal effect with one unit change in some X with ggeffects library. Moreover, you can illustrate how the predicted values change in comparison to the most typical observation.\n\nmarginal_effects = list(Log_GDP = c(8.984952, 8, 8.5, 9.5, 10),\n                        International_conflict = c(\"0\"),\n                        Regime = c(\"Autocratic\", \"Democratic\"))\n\n\nggpredict(model_int, marginal_effects) \n\n# Predicted values of Import\n\nRegime: Autocratic\n\nLog_GDP | Predicted |         95% CI\n------------------------------------\n   8.00 |    230.30 | 211.46, 249.13\n   8.50 |    291.43 | 272.06, 310.80\n   8.98 |    350.72 | 329.90, 371.54\n   9.50 |    413.69 | 390.51, 436.87\n  10.00 |    474.82 | 448.77, 500.88\n\nRegime: Democratic\n\nLog_GDP | Predicted |         95% CI\n------------------------------------\n   8.00 |    135.14 | 106.89, 163.38\n   8.50 |    196.27 | 170.13, 222.41\n   8.98 |    255.56 | 230.85, 280.27\n   9.50 |    318.53 | 294.54, 342.51\n  10.00 |    379.66 | 355.54, 403.78"
  }
]