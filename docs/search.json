[
  {
    "objectID": "ps405-d_1.html",
    "href": "ps405-d_1.html",
    "title": "Last Quarter’s Review",
    "section": "",
    "text": "We are expected to have installed R and RStudio, if not see the installing R section.\nIn the discussion section, we will focus on coding and practicing what we have learned in the lectures.\nOffice hours are on Tuesday, 11-12:30 Scott 110.\nQuestions?\n\n\nDownload script"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PS405 Linear Models",
    "section": "",
    "text": "This site is designed to support students enrolled in the PS405 Linear Models course. Here, you will find lab materials, which are also available on Canvas. In the section, we will focus on coding and practicing the concepts covered in the lectures.\n\n\n\n\n\n   Thursday\n   11:00 AM – 11:50 AM\n   Scott Hall 212\n\n\n\n\n\n\n   Tuesday\n   11:00 AM – 12:30 PM\n   Scott Hall 110"
  },
  {
    "objectID": "ps405-d_1.html#terminology",
    "href": "ps405-d_1.html#terminology",
    "title": "Last Quarter’s Review",
    "section": "Terminology",
    "text": "Terminology"
  },
  {
    "objectID": "ps405-d_1.html#coding-terminology",
    "href": "ps405-d_1.html#coding-terminology",
    "title": "Last Quarter’s Review",
    "section": "Coding Terminology",
    "text": "Coding Terminology\n\nCode Chunk\nTo insert a Code Chunk, you can use Ctrl+Alt+I on Windows and Cmd+Option+I on Mac. Run the whole chunk by clicking the green triangle, or one/multiple lines by using Ctrl + Enter or Command + Return on Mac.\n\nprint(\"Code Chunk\")\n\n[1] \"Code Chunk\"\n\n\n\n\nFunction and Arguments\nMost of the functions we want to run require an argument For example, the function print() above takes the argument “Code Chunk”.\n\nfunction(argument)\n\n\n\nData structures\nThere are many data structures, but the most important to know the following.\n\nObjects. Those are individual units, e.g. a number or a word.\n\n\nnumber = 1\nnumber\n\nword = \"Northwestern\"\nword\n\n[1] 1\n[1] \"Northwestern\"\n\n\n\nVectors. Vectors are collections of objects. To create one, you will need to use function c().\n\n\nnumbers = c(1, 2, 3)\nnumbers\n\n[1] 1 2 3\n\n\n\nDataframes. Dataframes are the most used data structure. Last quarter you spend a lot of time working with it. It is a table with data. Columns are called variables, and those are vectors. You can access a column using $ operator.\n\n\ndf = data.frame(numbers, \n                numbers_multiplied = numbers * 2)\ndf\ndf$numbers_multiplied\n\n  numbers numbers_multiplied\n1       1                  2\n2       2                  4\n3       3                  6\n[1] 2 4 6\n\n\n\n\nData classes\nWe work with various classes of data, and the analysis we perform depends heavily on these classes.\n\nNumeric. Continuous data.\n\n\nnumeric_class = c(1.2, 2.5, 7.3)\nnumeric_class\nclass(numeric_class)\n\n[1] 1.2 2.5 7.3\n[1] \"numeric\"\n\n\n\nInteger. Whole numbers (e.g., count data).\n\n\ninteger_class = c(1:3)\nclass(integer_class)\n\n[1] \"integer\"\n\n\n\nCharacter. Usually, represent textual data.\n\n\nword\n\n[1] \"Northwestern\"\n\nclass(word)\n\n[1] \"character\"\n\n\n\nFactor. Categorical variables, where each value is treated as an identifier for a category.\n\n\ncolors = c(\"blue\", \"green\")\nclass(colors)\n\n[1] \"character\"\n\n\nAs you noticed, R did not identify the class of data correctly. We can change it using as.factor() function. You can easily change the class of your variable (as.numeric(), as.integer(), as.character())\n\ncolors = as.factor(colors)\nclass(colors)\n\n[1] \"factor\"\n\n\n\n\nLibraries\nQuite frequently, we use additional libraries to extend the capabilities of R. I’m sure you remember tidyverse. Let’s load it.\n\nlibrary(tidyverse)\n\nIf you updated your R or recently downloaded it, you can easily install libraries using the function install.packages().\n\n\nPipes\nPipes (%&gt;% or |&gt;) are helpful for streamlining the coding. They introduce linearity to the process of writing the code. In plain English, a pipe translates to “take an object, and then”.\n\nnumbers %&gt;%\n  print()\n\n[1] 1 2 3"
  },
  {
    "objectID": "ps405-d_2.html",
    "href": "ps405-d_2.html",
    "title": "Simple Linear Regression",
    "section": "",
    "text": "Download the data\nOrganize your directory\n\n\nDownload script\n\n\n\nDownload data"
  },
  {
    "objectID": "ps405-d_2.html#model-building",
    "href": "ps405-d_2.html#model-building",
    "title": "Simple Linear Regression",
    "section": "Model Building",
    "text": "Model Building\nLet’s run a simple model, and then check it’s summary.\n\nbasic_model = lm(Ladder_score ~ Social_support, whr)\n  \nsummary(basic_model)\n\n\nCall:\nlm(formula = Ladder_score ~ Social_support, data = whr)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.76562 -0.36701  0.01165  0.46577  1.49971 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     -0.3428     0.3386  -1.013    0.313    \nSocial_support   7.3618     0.4183  17.599   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6304 on 135 degrees of freedom\nMultiple R-squared:  0.6964,    Adjusted R-squared:  0.6942 \nF-statistic: 309.7 on 1 and 135 DF,  p-value: &lt; 2.2e-16\n\n\nA one unit increase in Social Support is associated with a 7.4 increase in the happiness score. What is the maximum value the Happiness Score can take?\n\nmax(whr$Ladder_score)\n\n[1] 7.804\n\n\nAnd now, let’s draw a histogram of the Social Support. So, how much does this model tell us?\n\nggplot(whr) +\n  ...(aes(x = Social_support))\n\nLet’s correct the Social_support variable a bit, transforming it to 0-100 scale. What do you think about the model now? What do you think about \\(R^2\\)?\n\nwhr = whr %&gt;%\n  mutate(Social_support_percentage = Social_support * 100)\n\nadjusted_model = lm(Ladder_score ~ Social_support_percentage, whr)\n  \nsummary(adjusted_model)\n\n\nCall:\nlm(formula = Ladder_score ~ Social_support_percentage, data = whr)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.76562 -0.36701  0.01165  0.46577  1.49971 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)               -0.342811   0.338568  -1.013    0.313    \nSocial_support_percentage  0.073618   0.004183  17.599   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6304 on 135 degrees of freedom\nMultiple R-squared:  0.6964,    Adjusted R-squared:  0.6942 \nF-statistic: 309.7 on 1 and 135 DF,  p-value: &lt; 2.2e-16\n\n\nLet’s write this regression formula out. Do you remember the general form?\n\\[\nY = \\beta_0 + \\beta_1X_1+\\epsilon\n\\]\nIn our case, this can be presented as\n\\[\n\\text{Happines} = -0.34 + 0.07\\text{ Social Support} + e\n\\]\nAlternatively,\n\\[\nY = -0.34+0.07x+u\n\\]\nNow, visualize the regression.\n\nggplot(whr, aes(x = Social_support_percentage, y = Ladder_score)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(x = \"Social Support (%)\",\n       y = \"Happiness Score\")"
  },
  {
    "objectID": "ps405-d_2.html#diagnostics",
    "href": "ps405-d_2.html#diagnostics",
    "title": "Simple Linear Regression",
    "section": "Diagnostics",
    "text": "Diagnostics\nLet’s analyze the regression. First, extract the residuals and plot their distribution. Does it follow \\(N(0, \\sigma^2)\\)?\n\nres = adjusted_model$residuals\n\nggplot() +\n  geom_histogram(aes(x = res), bins = 20) +\n  geom_vline(xintercept = mean(res), color = \"red\", size = 1.5)\n\n\n\n\n\n\n\n\nNow we need to check the constant variance assumption. Does it hold? What term is used to describe this satisfied assumption?\n\nyhat = adjusted_model$fitted.values\n\nggplot() +\n  geom_point(aes(x = yhat, y = res)) +\n  geom_hline(yintercept = 0, color = \"blue\") +\n  labs(title = \"Residuals vs fitted values plot\")\n\n\n\n\n\n\n\n\nExplore different patterns below"
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "PS405 Linear Models",
    "section": "Schedule",
    "text": "Schedule\n\n\n\n\n\nWeek\n\n\nTitle\n\n\nLink\n\n\nCode\n\n\nData\n\n\n\n\n\n\n1\n\n\nLast Quarter’s Review\n\n\n\n\n\n\n\n\n \n\n\n\n\n2\n\n\nSimple Linear Regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n3\n\n\nMultiple Linear Regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n4\n\n\nReview and Confidence Intervals\n\n\n\n\n\n\n\n\n\n\n\n\n\n5\n\n\nPresenting Results of Regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#description",
    "href": "index.html#description",
    "title": "PS405 Linear Models",
    "section": "",
    "text": "This site is designed to support students enrolled in the PS405 Linear Models course. Here, you will find lab materials, which are also available on Canvas. In the section, we will focus on coding and practicing the concepts covered in the lectures.\n\n\n\n\n\n   Thursday\n   11:00 AM – 11:50 AM\n   Scott Hall 212\n\n\n\n\n\n\n   Tuesday\n   11:00 AM – 12:30 PM\n   Scott Hall 110"
  },
  {
    "objectID": "index.html#additional-resources",
    "href": "index.html#additional-resources",
    "title": "PS405 Linear Models",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nHelpful Regression Resources\n\nStep-by-step regression guide\n\n\n\nData sources\n\nPolitical Science datasets\n\n\n\nVisualization\n\nIntroduction to ggplot2\nMaps/Networks/Advanced vizualisation with ggplot2\nMaking interactive plots with ggplot2"
  },
  {
    "objectID": "ps405-d_3.html",
    "href": "ps405-d_3.html",
    "title": "Multiple Linear Regression",
    "section": "",
    "text": "Congrats with submitting the first HW! How are you feeling?\nThe discussion section structure (review, comments about HW, new material and exercises). I would be happy to hear your feedback after the classes or via email.\n\n\nDownload script\n\n\n\nDownload data"
  },
  {
    "objectID": "ps405-d_3.html#fixed-effects",
    "href": "ps405-d_3.html#fixed-effects",
    "title": "Multiple Linear Regression",
    "section": "Fixed Effects",
    "text": "Fixed Effects\nLet’s explore how leader’s tenure is associated with the number of individuals in the government. We start with the simple linear regression. Take a moment to interpret the result and \\(R^2\\).\n\nlm(n_individuals ~ leaderexperience_continuous, whogov) %&gt;%\n  summary()\n\n\nCall:\nlm(formula = n_individuals ~ leaderexperience_continuous, data = whogov)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-28.666  -6.937  -1.937   5.301 109.063 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 23.59948    0.16232  145.39   &lt;2e-16 ***\nleaderexperience_continuous  0.33702    0.01627   20.71   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.21 on 9151 degrees of freedom\nMultiple R-squared:  0.04477,   Adjusted R-squared:  0.04467 \nF-statistic: 428.9 on 1 and 9151 DF,  p-value: &lt; 2.2e-16\n\n\nTake a moment and draw a scatterplot for n_individuals and leaderexperience_continuous. Add a regression line to the plot.\n\n...\n\nNow, let’s add a categorical variable, indep, to the model. By doing so, we assume that the association between the leader’s tenure and the number of individuals in the government differs depending on whether the leader is independent or partisan.\nPractically, this could be done in multiple ways. First, let’s discuss introduction of fixed effects to our model. Moreover, this is a Multiple linear regression!\n\nmodel_fe = lm(n_individuals ~ leaderexperience_continuous + indep, whogov) \nsummary(model_fe)\n\n\nCall:\nlm(formula = n_individuals ~ leaderexperience_continuous + indep, \n    data = whogov)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.437  -7.078  -1.796   5.377 108.632 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 24.01096    0.16605  144.60   &lt;2e-16 ***\nleaderexperience_continuous  0.35700    0.01617   22.08   &lt;2e-16 ***\nindepIndependent            -3.02909    0.29988  -10.10   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.06 on 9126 degrees of freedom\n  (24 observations deleted due to missingness)\nMultiple R-squared:  0.05649,   Adjusted R-squared:  0.05628 \nF-statistic: 273.2 on 2 and 9126 DF,  p-value: &lt; 2.2e-16\n\n\nWe will use ggeffects library for visualization of regression with the fixed effects. This is sort of an addition to ggplot2 library from tidyverse. Don’t forget to install it using install.packages()!\n\nlibrary(ggeffects)\n\nThen, visualize the result. What can we see?\n\nggpredict(model_fe, terms = c(\"leaderexperience_continuous\", \"indep\")) %&gt;%\n  plot()\n\n\n\n\n\n\n\n\nLet’s customize the plot. It should be relatively straightforward given we know ggplot functions. Details for the customization of plot() function can be found on ggeffects website.\n\nggpredict(model_fe, terms= c(\"leaderexperience_continuous\", \"indep\")) %&gt;%\n  plot(show_ci = F) +\n  labs(title = \"Fixed Effects Regression\",\n       x = \"Tenure of a Leader\",\n       y = \"Number of Individuals in a Cabinet\",\n       color = \"Leader's Status\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nSome common fixed effects include:\n\nCountry/Region/State\nIndividual leaders/Parties\nYear/Time\nPolicy presence or absence\n\nBy introducing fixed effects, we are able to control for unobserved confounders that vary across the units (not within!)."
  },
  {
    "objectID": "ps405-d_3.html#interactions",
    "href": "ps405-d_3.html#interactions",
    "title": "Multiple Linear Regression",
    "section": "Interactions",
    "text": "Interactions\nOften dummy variables are used to introduce an interaction term in the model. We will explore the association between Perceptions_of_corruption and number of people in the cabinet (n_individuals) depending on the independence of the party leader.\nThe task isn’t trivial as now we planning to use data from two datasets, Let’s subset those.\n\nwhr_subset = whr %&gt;%\n  select(Country_name, Perceptions_of_corruption)\n\nwhogov_subset = whogov %&gt;%\n  filter(year == 2021) %&gt;%\n  select(country_name, n_individuals, indep)\n\nNow, we are merging them. It’s not easy to understand what’s going on, but here is a great resource on joins (check “the {dplyr} way”)!\n\nwhr_whogov = whr_subset %&gt;%\n  left_join(whogov_subset, by = c(\"Country_name\" = \"country_name\")) \n\nCheck the result\n\nhead(whr_whogov)\n\n  Country_name Perceptions_of_corruption n_individuals           indep\n1      Finland                     0.182            23 Non-independent\n2      Denmark                     0.196            24 Non-independent\n3      Iceland                     0.668            15 Non-independent\n4       Israel                     0.708            33 Non-independent\n5  Netherlands                     0.379            18 Non-independent\n6       Sweden                     0.202            26 Non-independent\n\n\nNow, to interact variables we need to use asterisk *, i.e. multiplication.\n\nmodel_in = lm(Perceptions_of_corruption ~ n_individuals * indep, whr_whogov)\nsummary(model_in)\n\n\nCall:\nlm(formula = Perceptions_of_corruption ~ n_individuals * indep, \n    data = whr_whogov)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.54000 -0.05737  0.04300  0.10864  0.24382 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                     0.575192   0.061646   9.331 5.59e-16 ***\nn_individuals                   0.004818   0.002151   2.240   0.0269 *  \nindepIndependent                0.386220   0.159570   2.420   0.0170 *  \nn_individuals:indepIndependent -0.010703   0.005501  -1.946   0.0540 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1737 on 123 degrees of freedom\n  (10 observations deleted due to missingness)\nMultiple R-squared:  0.08324,   Adjusted R-squared:  0.06088 \nF-statistic: 3.723 on 3 and 123 DF,  p-value: 0.01326\n\n\nLet’s plot the result. Try to change show_ci to TRUE. Does it explain the p-value now?\n\nggpredict(model_in, terms= c(\"n_individuals\", \"indep\")) %&gt;%\n  plot(show_ci = FALSE) +\n  labs(title = \"Regression with Interaction Term\",\n       x = \"Number of Individuals in a Cabinet\",\n       y = \"Perception of Corruption\",\n       color = \"Leader's Status\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nAnd you can easily simulate the data (i.e., calculate the marginal effect) using ggpredict(). For example,\n\nggpredict(model_in, terms= c(\"n_individuals [12]\", \"indep [Independent]\"))\n\n# Predicted values of Perceptions_of_corruption\n\nn_individuals | Predicted |     95% CI\n--------------------------------------\n           12 |      0.89 | 0.71, 1.07"
  },
  {
    "objectID": "ps405-d_3.html#using-dummy-variables-in-the-regression",
    "href": "ps405-d_3.html#using-dummy-variables-in-the-regression",
    "title": "Multiple Linear Regression",
    "section": "Using dummy variables in the regression",
    "text": "Using dummy variables in the regression\nToday we are working with WhoGov dataset. As usual, I recomment taking a look at their codebook.\n\nwhogov = read.csv(\"data/WhoGov.csv\")\n\nFirst of all, these are the following variables we are going to work with today:\n\ncountry_name is a country name\nn_individuals number of unique persons in the cabinet\nleaderexperience_continuous the number of years the person has been leader of the country in total.\nleader_party party of the leader\nsystem_category the regime type\n\nStart with exploring the distribution of number of unique persons in the cabinet (n_individuals)\n\nggplot(whogov) +\n  geom_histogram(aes(x = n_individuals)) \n\n\n\n\n\n\n\n\nPresent the descriptive statistics of n_individuals variable.\n\n...\n\nLet’s explore whether a leader of a country being independent from a party leads to more or fewer people in their cabinet. First, let’s create a dummy variable indicating if a leader is independent or non-independent. You can use 1 or 0 instead, but to make it more readable we stick to more transparent labels.\n\nwhogov = whogov %&gt;%\n  mutate(indep = ifelse(leader_party == \"independent\", \"Independent\", \"Non-independent\"))\n\nNow, build a simple model and explore the effect.\n\nlm(n_individuals ~ indep, whogov) %&gt;%\n  summary()\n\n\nCall:\nlm(formula = n_individuals ~ indep, data = whogov)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.342  -7.342  -2.342   5.658 106.658 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           24.0592     0.2761  87.148   &lt;2e-16 ***\nindepNon-independent   2.2833     0.3058   7.466    9e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.35 on 9127 degrees of freedom\n  (24 пропущенных наблюдений удалены)\nMultiple R-squared:  0.006071,  Adjusted R-squared:  0.005962 \nF-statistic: 55.75 on 1 and 9127 DF,  p-value: 9.003e-14\n\n\nWhat if we want to relevel the indep variable to know the effect relative to Non-independent leader?\n\nwhogov$indep = relevel(whogov$indep, ref = \"Non-independent\")\n\nOops! This is why classes of data are important. Fix it!\n\nwhogov$indep = as.factor(whogov$indep)\n\nNow we can relevel the variable\n\nwhogov$indep = relevel(whogov$indep, ref = \"Non-independent\")\n\nCompare the models. Does the result sound reasonable? Pretty much. This is simply an inverse. But things get way more interesting if categorical variable has more than 2 levels. You will see this later on. For now, let’s interpret the result.\n\nlm(n_individuals ~ indep, whogov) %&gt;%\n  summary()\n\n\nCall:\nlm(formula = n_individuals ~ indep, data = whogov)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.342  -7.342  -2.342   5.658 106.658 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       26.3425     0.1315 200.264   &lt;2e-16 ***\nindepIndependent  -2.2833     0.3058  -7.466    9e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.35 on 9127 degrees of freedom\n  (24 пропущенных наблюдений удалены)\nMultiple R-squared:  0.006071,  Adjusted R-squared:  0.005962 \nF-statistic: 55.75 on 1 and 9127 DF,  p-value: 9.003e-14"
  },
  {
    "objectID": "ps405-d_3.html#dummy-variables-and-ols-regression",
    "href": "ps405-d_3.html#dummy-variables-and-ols-regression",
    "title": "Multiple Linear Regression",
    "section": "Dummy variables and OLS regression",
    "text": "Dummy variables and OLS regression\nToday we are working with WhoGov dataset. As usual, I recomment taking a look at their codebook.\n\nwhogov = read.csv(\"data/WhoGov.csv\")\n\nFirst of all, these are the following variables we are going to work with today:\n\ncountry_name is a country name\nn_individuals number of unique persons in the cabinet\nleaderexperience_continuous the number of years the person has been leader of the country in total.\nleader_party party of the leader\n\nStart with exploring the distribution of number of unique persons in the cabinet (n_individuals)\n\nggplot(whogov) +\n  geom_histogram(aes(x = n_individuals)) \n\n\n\n\n\n\n\n\nPresent the descriptive statistics of n_individuals variable.\n\n...\n\nLet’s examine whether a country’s leader being independent from a political party is associated with having more or fewer members in their cabinet. First, let’s create a dummy variable indicating if a leader is independent or non-independent. You can use 1 or 0 instead, but to make it more readable here we stick to more transparent labels.\n\nwhogov = whogov %&gt;%\n  mutate(indep = ifelse(leader_party == \"independent\", \"Independent\", \"Non-independent\"))\n\nNow, build a simple model and explore the effect. On average, being a non-independent (i.e. partisan) leader is associated with having 2.28 more members in their cabinet compared to independent leaders.\n\nlm(n_individuals ~ indep, whogov) %&gt;%\n  summary()\n\n\nCall:\nlm(formula = n_individuals ~ indep, data = whogov)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.342  -7.342  -2.342   5.658 106.658 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           24.0592     0.2761  87.148   &lt;2e-16 ***\nindepNon-independent   2.2833     0.3058   7.466    9e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.35 on 9127 degrees of freedom\n  (24 observations deleted due to missingness)\nMultiple R-squared:  0.006071,  Adjusted R-squared:  0.005962 \nF-statistic: 55.75 on 1 and 9127 DF,  p-value: 9.003e-14\n\n\nWhat if we want to know the effect relative to Non-independent leader? Let’s relevel() the variable!\n\nwhogov$indep = relevel(whogov$indep, ref = \"Non-independent\")\n\nOops! This is why classes of data are important. Fix it!\n\nwhogov$indep = as.factor(whogov$indep)\n\nNow we can relevel the variable\n\nwhogov$indep = relevel(whogov$indep, ref = \"Non-independent\")\n\nCompare the models. Does the result sound reasonable? Pretty much. This is simply an inverse. But things get way more interesting if a categorical variable has more than 2 levels. You will see this later on.\n\nlm(n_individuals ~ indep, whogov) %&gt;%\n  summary()\n\n\nCall:\nlm(formula = n_individuals ~ indep, data = whogov)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.342  -7.342  -2.342   5.658 106.658 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       26.3425     0.1315 200.264   &lt;2e-16 ***\nindepIndependent  -2.2833     0.3058  -7.466    9e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.35 on 9127 degrees of freedom\n  (24 observations deleted due to missingness)\nMultiple R-squared:  0.006071,  Adjusted R-squared:  0.005962 \nF-statistic: 55.75 on 1 and 9127 DF,  p-value: 9.003e-14"
  },
  {
    "objectID": "index.html#grade-increase-policy",
    "href": "index.html#grade-increase-policy",
    "title": "PS405 Linear Models",
    "section": "Grade increase policy",
    "text": "Grade increase policy\nTo improve your homework grade, you should submit the exercises from the corresponding lab session held during the week the homework was assigned. For instance, if you wish to improve the grade for the first homework, which was assigned on January 16th, you should submit the completed exercises from the second lab, which took place on the same day. If you prefer not to check the dates each time, given that homework is assigned each week starting from week 2, you can use the formula:\n\\[\n\\text{E}[\\text{Lab Number}|\\text{Pset is assigned each week}] = \\text{Pset Number} + 1\n\\]"
  },
  {
    "objectID": "index.html#pset-grade-increase-policy",
    "href": "index.html#pset-grade-increase-policy",
    "title": "PS405 Linear Models",
    "section": "Pset Grade Increase Policy",
    "text": "Pset Grade Increase Policy\nTo improve your grade for the problem set, you should submit the exercises from the corresponding lab session held during the week the homework was assigned. Exercises can be found at the end of each lab. You can increase grades for every problem set, except for the last one before the final. The maximum possible increase is two points.\nFor instance, if you wish to improve the grade for the first homework, which was assigned on January 16th, you should submit the completed exercises from the second lab, which took place on the same day. If you prefer not to check the dates each time, given that homework is assigned each week starting from week 2, you can use the formula:\n\\[\n\\text{Lab Number}|\\text{Pset is assigned each week} = \\text{Pset Number} + 1\n\\]\nAfter the grades are released, you have one week to submit the .qmd file via email to artur.baranov@u.northwestern.edu."
  },
  {
    "objectID": "ps405-d_4.html",
    "href": "ps405-d_4.html",
    "title": "Review and Confidence Intervals",
    "section": "",
    "text": "Congrats passing through the first quiz! How are you feeling?\nGrades for the psets are out.\n\n\nDownload script\n\n\n\nDownload data"
  },
  {
    "objectID": "ps405-d_4.html#latex-issues",
    "href": "ps405-d_4.html#latex-issues",
    "title": "Review and Confidence Intervals",
    "section": "\\(\\LaTeX\\) issues",
    "text": "\\(\\LaTeX\\) issues\nIntegration of R, Python, markdown, Latex and other useful languages incredibly useful. But it comes to a price that researchers should be careful. Any \\(\\LaTeX\\) code should go within two $ dollar signs $. For example, an inline formula looks like this: $ Y = 10 $, which produces the following result: \\(Y = 10\\). Alternatively, you can use a double dollar sign to start a “chunk” for latex. For example:\n\\[\nY = \\beta_0 + \\beta_1X + u\n\\]"
  },
  {
    "objectID": "ps405-d_4.html#useful-functions",
    "href": "ps405-d_4.html#useful-functions",
    "title": "Review and Confidence Intervals",
    "section": "Useful functions",
    "text": "Useful functions\nSometimes you might want to visualize some mathematical functions using geom_function(). In the HW, you were asked to plot an OLS regression vs the true data generating process. For this purpose example below is super useful (however, geom_abline() for this particular task is perfect, too).\n\nset.seed(123)\n\nexample_data = data.frame(x = rnorm(100,\n                                    mean = 2,\n                                    sd = 15),\n                          y = rnorm(100,\n                                    mean = 2,\n                                    sd = 15) * rnorm(100))\n\nggplot(example_data, aes(x = x, y = y)) +\n  geom_point() +\n  geom_smooth(aes(color = \"Fitted\"), method = \"lm\", se = F) +\n  geom_function(aes(color = \"Known\"), fun = function(x){1 + 0.5 * x}, size = 1.2) \n\n\n\n\n\n\n\n\nSometimes it’s useful to visualize, say, polynomials! How does \\(x^3\\) look like?\n\nggplot() +\n  geom_function(fun = function(x){x^2}) +\n  geom_vline(xintercept = 0) +\n  xlim(-1, 1)"
  },
  {
    "objectID": "ps405-d_4.html#fixed-effects",
    "href": "ps405-d_4.html#fixed-effects",
    "title": "Review and Confidence Intervals",
    "section": "Fixed Effects",
    "text": "Fixed Effects\nWhen we introduce a dummy variable into the model, we quite often are interested in controlling for unobserved heterogeneity by allowing each category to have its own intercept. This is referred to as fixed effects.\nFirst, let’s create a dummy variable indicating if a leader is independent or Partisan. You can use 1 or 0 instead, but to make it more readable here we stick to more transparent labels.\n\nwhogov = whogov %&gt;%\n  mutate(indep = ifelse(leader_party == \"independent\", \"Independent\", \"Partisan\"))\n\nDon’t forget about the class of the variable!\n\nwhogov$indep = as.factor(whogov$indep)\n\nTake a moment to think about what unobserved heterogeneity we can control for by including whether a leader is independent or partisan in the model.\n\nmodel_fe = lm(n_individuals ~ leaderexperience_continuous + indep, whogov) \nsummary(model_fe)\n\n\nCall:\nlm(formula = n_individuals ~ leaderexperience_continuous + indep, \n    data = whogov)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.437  -7.078  -1.796   5.377 108.632 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 20.98188    0.30295   69.26   &lt;2e-16 ***\nleaderexperience_continuous  0.35700    0.01617   22.08   &lt;2e-16 ***\nindepPartisan                3.02909    0.29988   10.10   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.06 on 9126 degrees of freedom\n  (24 observations deleted due to missingness)\nMultiple R-squared:  0.05649,   Adjusted R-squared:  0.05628 \nF-statistic: 273.2 on 2 and 9126 DF,  p-value: &lt; 2.2e-16\n\n\nLet’s relevel to get the results for Independent candidates.\n\nwhogov$indep = relevel(whogov$indep, ref = \"Partisan\")\nmodel_fe = lm(n_individuals ~ leaderexperience_continuous + indep, whogov) \nsummary(model_fe)\n\n\nCall:\nlm(formula = n_individuals ~ leaderexperience_continuous + indep, \n    data = whogov)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.437  -7.078  -1.796   5.377 108.632 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 24.01096    0.16605  144.60   &lt;2e-16 ***\nleaderexperience_continuous  0.35700    0.01617   22.08   &lt;2e-16 ***\nindepIndependent            -3.02909    0.29988  -10.10   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.06 on 9126 degrees of freedom\n  (24 observations deleted due to missingness)\nMultiple R-squared:  0.05649,   Adjusted R-squared:  0.05628 \nF-statistic: 273.2 on 2 and 9126 DF,  p-value: &lt; 2.2e-16\n\n\nTo understand what’s going on in the model we might want to visualize the result. Load the ggeffects library.\n\nlibrary(ggeffects)\n\nThen, visualize the result. What can we see?\n\nggpredict(model_fe, terms = c(\"leaderexperience_continuous\", \"indep\")) %&gt;%\n  plot() +\n  labs(title = \"Fixed Effects Regression\",\n       x = \"Tenure of a Leader\",\n       y = \"Number of Individuals in a Cabinet\",\n       color = \"Leader's Status\") +\n  theme_bw()"
  },
  {
    "objectID": "ps405-d_4.html#interactions",
    "href": "ps405-d_4.html#interactions",
    "title": "Review and Confidence Intervals",
    "section": "Interactions",
    "text": "Interactions\nOften dummy variables are used to introduce an interaction term in the model. We will explore the association between Perceptions_of_corruption and number of people in the cabinet (n_individuals) depending on the independence of the party leader.\nThe task isn’t trivial as now we planning to use data from two datasets, Let’s subset those.\n\nwhr_subset = whr %&gt;%\n  select(Country_name, Perceptions_of_corruption)\n\nwhogov_subset = whogov %&gt;%\n  filter(year == 2021) %&gt;%\n  select(country_name, n_individuals, indep)\n\nNow, we are merging them. Once again, there is a great resource for joins (check “the {dplyr} way”)!\n\nwhr_whogov = whr_subset %&gt;%\n  left_join(whogov_subset, by = c(\"Country_name\" = \"country_name\")) \n\nCheck the result of the left_join()\n\nhead(whr_whogov)\n\n  Country_name Perceptions_of_corruption n_individuals    indep\n1      Finland                     0.182            23 Partisan\n2      Denmark                     0.196            24 Partisan\n3      Iceland                     0.668            15 Partisan\n4       Israel                     0.708            33 Partisan\n5  Netherlands                     0.379            18 Partisan\n6       Sweden                     0.202            26 Partisan\n\n\nNow, let’s interact the variable\n\nmodel_in = lm(Perceptions_of_corruption ~ n_individuals * indep, whr_whogov)\nsummary(model_in)\n\n\nCall:\nlm(formula = Perceptions_of_corruption ~ n_individuals * indep, \n    data = whr_whogov)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.54000 -0.05737  0.04300  0.10864  0.24382 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                     0.575192   0.061646   9.331 5.59e-16 ***\nn_individuals                   0.004818   0.002151   2.240   0.0269 *  \nindepIndependent                0.386220   0.159570   2.420   0.0170 *  \nn_individuals:indepIndependent -0.010703   0.005501  -1.946   0.0540 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1737 on 123 degrees of freedom\n  (10 observations deleted due to missingness)\nMultiple R-squared:  0.08324,   Adjusted R-squared:  0.06088 \nF-statistic: 3.723 on 3 and 123 DF,  p-value: 0.01326\n\n\nLet’s plot the result.\n\nggpredict(model_in, terms= c(\"n_individuals\", \"indep\")) %&gt;%\n  plot(show_ci = FALSE) +\n  labs(title = \"Regression with Interaction Term\",\n       x = \"Number of Individuals in a Cabinet\",\n       y = \"Perception of Corruption\",\n       color = \"Leader's Status\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nI guess after solving pset and quiz you realize why interpreting interactions is hard? You can easily simulate the data (i.e., calculate the marginal effect) using ggpredict(). For example,\n\nggpredict(model_in, terms= c(\"n_individuals [12]\", \"indep [Independent]\"))\n\n# Predicted values of Perceptions_of_corruption\n\nn_individuals | Predicted |     95% CI\n--------------------------------------\n           12 |      0.89 | 0.71, 1.07"
  },
  {
    "objectID": "ps405-d_4.html#transformations",
    "href": "ps405-d_4.html#transformations",
    "title": "Confidence Intervals and Hypothesis Testing",
    "section": "Transformations",
    "text": "Transformations"
  },
  {
    "objectID": "ps405-d_4.html#iv-transformations",
    "href": "ps405-d_4.html#iv-transformations",
    "title": "Review and Confidence Intervals",
    "section": "IV Transformations",
    "text": "IV Transformations\nOne of the assumptions for OLS is that there is a linear relationship between the dependent and independent variables. However, this quite often not the case. Let’s reverse the correction made in World Happiness report data. See below. Does it look linear?\n\nggplot(whr) +\n  geom_point(aes(x = exp(Logged_GDP_per_capita), y = Ladder_score)) +\n  labs(x = \"GDP per capita\")\n\n\n\n\n\n\n\n\nIt doesn’t. It’s hard to describe this relationship in a linear manner. Natural log would explain this better, right?\n\nggplot(whr, aes(x = exp(Logged_GDP_per_capita), y = Ladder_score)) +\n  geom_point() +\n  geom_function(fun = function(x){log(x) - 4}) +\n  labs(x = \"GDP per capita\")\n\n\n\n\n\n\n\n\nThis is why we use the natural logarithm to transform GDP per capita. The transformation reveals a linear relationship between the two variables, allowing us to capture non-linear patterns in a linear format when using OLS regression. Another commonly used transformation is quadratic (\\(x^2\\)), which serves the same purpose of addressing non-linear relationships. We call latter ones polynomials.\n\nggplot(whr, aes(x = Logged_GDP_per_capita, y = Ladder_score)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "data_process.html",
    "href": "data_process.html",
    "title": "Untitled",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nsipri = read.csv(\"import-export-values_1950-2024.csv\")\nsipri = sipri %&gt;%\n  select(-X2024)\n\n\nsipri = sipri %&gt;%\n  pivot_longer(2:75,\n               names_to = \"Year\",\n               values_to = \"Import\")\n\nsipri = sipri %&gt;%\n  mutate(Year = str_remove(Year, \"X\"))\n\nsipri = na.omit(sipri)\n\n\nload(url(\"https://github.com/vdeminstitute/vdemdata/raw/6bee8e170578fe8ccdc1414ae239c5e870996bc0/data/vdem.RData\"))\n\ne_v2x_polyarchy_5C\n\nvdem_sub = vdem %&gt;%\n  select(year, country_name, e_v2x_polyarchy_4C)\n\nvdem_sub$year = as.character(vdem_sub$year)\n\nmerger = sipri %&gt;%\n  left_join(vdem_sub, by = c('Year' = 'year', 'Recipient' = 'country_name'))\n\nmerger = na.omit(merger)\n\nmerger = merger %&gt;%\n  mutate(Regime = case_when(e_v2x_polyarchy_4C == 0 ~ \"Autocratic\",\n                            e_v2x_polyarchy_4C == 0.333 ~ \"Electoral Authoritarian\",\n                            e_v2x_polyarchy_4C == 0.667 ~ \"Minimally Democratic\",\n                            e_v2x_polyarchy_4C == 1 ~ \"Democratic\"))\n\nmerger = merger %&gt;%\n  select(-e_v2x_polyarchy_4C)\n\n# write.csv(merger, \"sipri.csv\", row.names = F)"
  },
  {
    "objectID": "ps405-d_5.html",
    "href": "ps405-d_5.html",
    "title": "Presenting Results of Regression",
    "section": "",
    "text": "Review of the previous week\n\n\n\n\n\n\nReview\n\n\n\nStart with loading the tidyverse library and the Who Governs data.\n\nlibrary(tidyverse)\n\nwhogov = read.csv(\"data/WhoGov.csv\")\n\nCalculate confidence intervals of n_total for each system_category.\nVisualize the calculated confidence intervals.\nggeffects\n\n\n\n\nReview of the homework\nThe ggeffects library is incredibly helpful! And quite simple. You can use it for plotting the categorical data. One thing to note, make sure it’s a factor()! Check it out below.\n\nlibrary(ggeffects)\n\nint = lm(alertness ~ coffee * time, data = coffee_data)\n\nggpredict(int, terms = c(\"time\", \"coffee\")) %&gt;%\n  plot(connect_lines = TRUE) \n\n\n\n\n\n\n\n\n\n\nAgenda\n\n\nDevtools in R\nSometimes, it is helpful to utilize versions of packages that are under development. Those are impossible to install directly, but you can download them frob GitHub. To simplify this process, you need special package called devtools.\n\ninstall.packages(\"devtools\")\n\nNow, install the vdemdata library. This way we’ll be able to load the most current V-Dem dataset directly to the R.\n\ndevtools::install_github(\"vdeminstitute/vdemdata\")\n\nLet’s test it. We see the dataset is here! But for the future, this is the way to install packages that are not released yet.\n\nlibrary(vdemdata)\nvdem %&gt;%\n  select(country_name, year, histname, v2x_polyarchy) %&gt;%\n  head()\n\n  country_name year                 histname v2x_polyarchy\n1       Mexico 1789 Viceroyalty of New Spain         0.028\n2       Mexico 1790 Viceroyalty of New Spain         0.028\n3       Mexico 1791 Viceroyalty of New Spain         0.028\n4       Mexico 1792 Viceroyalty of New Spain         0.028\n5       Mexico 1793 Viceroyalty of New Spain         0.028\n6       Mexico 1794 Viceroyalty of New Spain         0.028\n\n\n\n\nMerging Datasets and Exploring the Data\nWe are working with SIPRI Arms Transfers Database. It contains information on all transfers of major conventional arms.\n\nRecipient of arms\nYear\nImport of arms\nRegime a V-Dem variable for political regime\n\n\nsipri = read.csv(\"data/sipri.csv\")\n\nNow, subset some variables from V-Dem. We are choosing the following variables:\n\ncountry_name\nyear\ne_gdp GDP of a country\ne_miinteco Armed conflict, international\ne_miinterc Armed conflict, internal\n\n\nvdem_variables = vdem %&gt;%\n  select(country_name, year, e_gdp, e_miinteco, e_miinterc)\n\nNote the syntax below. We are joining two dataframes by two variables: Recipient and Year, but in the V-Dem data those have different name or spelling.\n\nsipri_vdem = sipri %&gt;%\n  left_join(vdem_variables, by = c(\"Recipient\" = \"country_name\", \n                                   \"Year\" = \"year\"))\n\nhead(sipri_vdem)\n\n  Recipient Year Import                  Regime    e_gdp e_miinteco e_miinterc\n1     India 1950    141              Autocratic 42170.12          0          0\n2     India 1951    277 Electoral Authoritarian 42010.81          0          0\n3     India 1952    104    Minimally Democratic 43033.76          0          0\n4     India 1953    430    Minimally Democratic 44503.00          0          0\n5     India 1954    265    Minimally Democratic 45960.55          0          0\n6     India 1955    350    Minimally Democratic 47305.30          1          1\n\n\nFor our convenience, rename the variables in the newly created dataframe.\n\nsipri_vdem = sipri_vdem %&gt;%\n  rename(GDP = e_gdp,\n         International_conflict = e_miinteco,\n         Internal_conflict = e_miinterc)\n\nhead(sipri_vdem)\n\n  Recipient Year Import                  Regime      GDP International_conflict\n1     India 1950    141              Autocratic 42170.12                      0\n2     India 1951    277 Electoral Authoritarian 42010.81                      0\n3     India 1952    104    Minimally Democratic 43033.76                      0\n4     India 1953    430    Minimally Democratic 44503.00                      0\n5     India 1954    265    Minimally Democratic 45960.55                      0\n6     India 1955    350    Minimally Democratic 47305.30                      1\n  Internal_conflict\n1                 0\n2                 0\n3                 0\n4                 0\n5                 0\n6                 1\n\n\nExplore the GDP variable. Does it need a transformation?\n\nggplot(sipri_vdem) +\n  geom_histogram(aes(x = GDP))\n\n\n\n\n\n\n\n\nIt might be the case. But to double-check our assumption, let’s draw a boxplot. Take the log() of GDP directly in the plot. Did it get better?\n\nggplot(sipri_vdem) +\n  geom_boxplot(aes(y = GDP))\n\nWarning: Removed 436 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\nTherefore, let’s create a new variable Log_GDP.\n\nsipri_vdem = sipri_vdem %&gt;%\n  mutate(Log_GDP = log(GDP))\n\nTo explore multiple variables at once, it is useful to plot them in pairs plot. There’s a library GGally which is based on ggplot2, and it’s quite straightforward. Be careful with the wrong class identification! Can you notice anything?\n\nlibrary(GGally)\n\nsipri_vdem %&gt;%\n  ggpairs(columns = c(\"Import\", \"Regime\", \"Log_GDP\", \"International_conflict\", \"Internal_conflict\"))\n\n\n\n\n\n\n\n\n\n\nModel Building\nLet’s set up a basic model. We are interested in explaining the Import of arms. Is it related to the economic capacity of the state? We can use proxy Log_GDP.\n\nmodel_basic = lm(Import ~ Log_GDP, sipri_vdem)\nsummary(model_basic)\n\n\nCall:\nlm(formula = Import ~ Log_GDP, data = sipri_vdem)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-676.3 -222.9  -87.5   66.0 5291.1 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -718.034     29.032  -24.73   &lt;2e-16 ***\nLog_GDP      108.547      3.168   34.26   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 457.9 on 6439 degrees of freedom\n  (436 observations deleted due to missingness)\nMultiple R-squared:  0.1542,    Adjusted R-squared:  0.1541 \nF-statistic:  1174 on 1 and 6439 DF,  p-value: &lt; 2.2e-16\n\n\n\nmodel_fe = lm(Import ~ Log_GDP + Regime + International_conflict, sipri_vdem)\nsummary(model_fe)\n\n\nCall:\nlm(formula = Import ~ Log_GDP + Regime + International_conflict, \n    data = sipri_vdem)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-991.3 -217.9  -82.6   81.4 5169.6 \n\nCoefficients:\n                              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                   -783.055     36.852 -21.248  &lt; 2e-16 ***\nLog_GDP                        126.364      4.468  28.281  &lt; 2e-16 ***\nRegimeDemocratic               -95.328     17.191  -5.545 3.11e-08 ***\nRegimeElectoral Authoritarian -151.434     23.328  -6.491 9.45e-11 ***\nRegimeMinimally Democratic    -216.183     50.820  -4.254 2.15e-05 ***\nInternational_conflict         206.923     26.470   7.817 6.72e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 454.6 on 4347 degrees of freedom\n  (2524 observations deleted due to missingness)\nMultiple R-squared:  0.1995,    Adjusted R-squared:  0.1986 \nF-statistic: 216.6 on 5 and 4347 DF,  p-value: &lt; 2.2e-16\n\nggpredict(model_fe, terms = c(\"Log_GDP\", \"International_conflict\", \"Regime\")) %&gt;%\n  plot()\n\nSome of the focal terms are of type `character`. This may lead to\n  unexpected results. It is recommended to convert these variables to\n  factors before fitting the model.\n  The following variables are of type character: `Regime`\n\n\n\n\n\n\n\n\n\n\nlibrary(ggeffects)\nmodel_int = lm(Import ~ Log_GDP + Regime * International_conflict, sipri_vdem)\nsummary(model_int)\n\n\nCall:\nlm(formula = Import ~ Log_GDP + Regime * International_conflict, \n    data = sipri_vdem)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-985.0 -215.3  -82.0   79.6 5162.7 \n\nCoefficients:\n                                                     Estimate Std. Error\n(Intercept)                                           -776.75      36.82\nLog_GDP                                                126.42       4.46\nRegimeDemocratic                                      -113.15      17.62\nRegimeElectoral Authoritarian                         -158.83      23.96\nRegimeMinimally Democratic                            -220.30      51.06\nInternational_conflict                                 135.93      31.78\nRegimeDemocratic:International_conflict                274.66      62.10\nRegimeElectoral Authoritarian:International_conflict    83.20     102.08\nRegimeMinimally Democratic:International_conflict     -149.72     457.60\n                                                     t value Pr(&gt;|t|)    \n(Intercept)                                          -21.096  &lt; 2e-16 ***\nLog_GDP                                               28.344  &lt; 2e-16 ***\nRegimeDemocratic                                      -6.420 1.51e-10 ***\nRegimeElectoral Authoritarian                         -6.629 3.79e-11 ***\nRegimeMinimally Democratic                            -4.315 1.63e-05 ***\nInternational_conflict                                 4.277 1.94e-05 ***\nRegimeDemocratic:International_conflict                4.423 9.97e-06 ***\nRegimeElectoral Authoritarian:International_conflict   0.815    0.415    \nRegimeMinimally Democratic:International_conflict     -0.327    0.744    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 453.7 on 4344 degrees of freedom\n  (2524 observations deleted due to missingness)\nMultiple R-squared:  0.2031,    Adjusted R-squared:  0.2016 \nF-statistic: 138.4 on 8 and 4344 DF,  p-value: &lt; 2.2e-16\n\nggpredict(model_int, terms = c(\"Log_GDP\", \"International_conflict\", \"Regime\")) %&gt;%\n  plot() \n\nSome of the focal terms are of type `character`. This may lead to\n  unexpected results. It is recommended to convert these variables to\n  factors before fitting the model.\n  The following variables are of type character: `Regime`\n\n\n\n\n\n\n\n\n\nPresent the model\nLaTeX: write out the formula\nReport the results, tables\nReport the results, CI effects\nReport the results, plot\nReport the results, simulations\nWhy voters who value democracy participate in democratic backsliding State Control and the Effects of Foreign Relations on Bilateral Trade\n\n\nExercises\npractice joins"
  }
]